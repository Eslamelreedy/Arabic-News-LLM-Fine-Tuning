{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QREIjT47Un_J"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC-f-DzB1N8V",
        "outputId": "e492e791-bea0-40fb-a6cc-9ea0164e162e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU wandb"
      ],
      "metadata": {
        "id": "ryz-wgjm2kDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU json-repair==0.29.1"
      ],
      "metadata": {
        "id": "5SBi2b-_3e6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XItczDrqUbNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a508b80-85c6-441c-f41a-fd904b31ba7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m123.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.5/385.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU transformers==4.48.3 datasets==3.2.0 optimum==1.24.0\n",
        "!pip install -qU wandb\n",
        "!pip install -qU json-repair==0.29.1\n",
        "!pip install -qU vllm==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmQ1CrQyVuEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4fe5fd-f6be-472e-90f7-8e763147256d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meslamelredy\u001b[0m (\u001b[33meslamelredy-na\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "\n",
        "wandb.login(key=userdata.get('wandb'))\n",
        "hf_token= userdata.get(\"HF_TOKEN\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQ_qMyuZ5jCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "!cd LLaMA-Factory && pip install -e ."
      ],
      "metadata": {
        "id": "wqKIGHUQ-WBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a285b5-8582-4fa4-ca8c-7b90e324bc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 365, done.\u001b[K\n",
            "remote: Counting objects: 100% (365/365), done.\u001b[K\n",
            "remote: Compressing objects: 100% (279/279), done.\u001b[K\n",
            "remote: Total 365 (delta 81), reused 291 (delta 72), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (365/365), 10.03 MiB | 18.30 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n",
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers!=4.52.0,<=4.55.0,>=4.49.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: datasets<=3.6.0,>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (3.2.0)\n",
            "Collecting accelerate<=1.7.0,>=1.3.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting peft<=0.15.2,>=0.14.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tokenizers<=0.21.1,>=0.19.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting gradio<=5.31.0,>=4.38.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (3.10.0)\n",
            "Collecting tyro<0.9.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.8.1)\n",
            "Collecting numpy<2.0.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (1.16.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.10.0)\n",
            "Collecting modelscope>=1.14.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading modelscope-1.28.2-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.1.9)\n",
            "Collecting safetensors<=0.5.3 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fire (from llamafactory==0.9.4.dev0)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (6.0.2)\n",
            "Collecting pydantic<=2.10.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.35.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.116.1)\n",
            "Collecting sse-starlette (from llamafactory==0.9.4.dev0)\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting av (from llamafactory==0.9.4.dev0)\n",
            "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.34.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.12.15)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.10.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.6.1)\n",
            "Collecting gradio-client==1.10.1 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.11.1)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.14.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,<=4.55.0,>=4.49.0->llamafactory==0.9.4.dev0) (2024.11.6)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.4.dev0) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->llamafactory==0.9.4.dev0) (3.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.20.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.1.7)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.3.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.28.2-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.55.0-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: llamafactory, fire\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=27930 sha256=9595884dc050d88a48f8c797e932b8d3be94e413352497bbba4f860da0360f23\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gzh6neys/wheels/bd/34/05/1e3cb4b8f20c20631b411dc5157b4b150850c03496fa96c2c4\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=8615cc24544453ead613a4d3f399d4a2f3d9618bee9404191b2fbc217f1223a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built llamafactory fire\n",
            "Installing collected packages: shtab, safetensors, pydantic-core, numpy, fire, av, sse-starlette, pydantic, modelscope, tyro, tokenizers, gradio-client, transformers, gradio, accelerate, trl, peft, llamafactory\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.6.1\n",
            "    Uninstalling safetensors-0.6.1:\n",
            "      Successfully uninstalled safetensors-0.6.1\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.11.0\n",
            "    Uninstalling gradio_client-1.11.0:\n",
            "      Successfully uninstalled gradio_client-1.11.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.41.0\n",
            "    Uninstalling gradio-5.41.0:\n",
            "      Successfully uninstalled gradio-5.41.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.9.0\n",
            "    Uninstalling accelerate-1.9.0:\n",
            "      Successfully uninstalled accelerate-1.9.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.17.0\n",
            "    Uninstalling peft-0.17.0:\n",
            "      Successfully uninstalled peft-0.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.7.0 av-15.0.0 fire-0.7.0 gradio-5.31.0 gradio-client-1.10.1 llamafactory-0.9.4.dev0 modelscope-1.28.2 numpy-1.26.4 peft-0.15.2 pydantic-2.10.6 pydantic-core-2.27.2 safetensors-0.5.3 shtab-1.7.2 sse-starlette-3.0.2 tokenizers-0.21.1 transformers-4.55.0 trl-0.9.6 tyro-0.8.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "\n",
        "\n",
        "\n",
        "!rm -rf LLaMA-Factory\n",
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "!cd LLaMA-Factory && pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB9jy8fz5y6g",
        "outputId": "c97d6f44-6395-4f85-ab93-3970d49ca8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 365, done.\u001b[K\n",
            "remote: Counting objects: 100% (365/365), done.\u001b[K\n",
            "remote: Compressing objects: 100% (279/279), done.\u001b[K\n",
            "remote: Total 365 (delta 81), reused 291 (delta 72), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (365/365), 10.03 MiB | 12.35 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n",
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers!=4.52.0,<=4.55.0,>=4.49.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (4.55.0)\n",
            "Collecting datasets<=3.6.0,>=2.16.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting accelerate<=1.7.0,>=1.3.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting peft<=0.15.2,>=0.14.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tokenizers<=0.21.1,>=0.19.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting gradio<=5.31.0,>=4.38.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (3.10.0)\n",
            "Collecting tyro<0.9.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.8.1)\n",
            "Collecting numpy<2.0.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (1.16.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.10.0)\n",
            "Collecting modelscope>=1.14.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading modelscope-1.28.2-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.1.9)\n",
            "Collecting safetensors<=0.5.3 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fire (from llamafactory==0.9.4.dev0)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (6.0.2)\n",
            "Collecting pydantic<=2.10.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.35.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.116.1)\n",
            "Collecting sse-starlette (from llamafactory==0.9.4.dev0)\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting av (from llamafactory==0.9.4.dev0)\n",
            "  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.34.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.12.15)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.10.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.6.1)\n",
            "Collecting gradio-client==1.10.1 (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.11.1)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.14.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.1.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,<=4.55.0,>=4.49.0->llamafactory==0.9.4.dev0) (2024.11.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (13.9.4)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.17.0)\n",
            "Collecting shtab>=1.5.6 (from tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.20.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->llamafactory==0.9.4.dev0) (3.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.3.8)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.22)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
            "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Downloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m156.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "Downloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "Downloading modelscope-1.28.2-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m180.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m154.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m156.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: llamafactory, fire\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=27930 sha256=c879bbde8573e6ac3644fa1cb228a55c061cdcdde790c0c95b4767442ac0936c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lo89teh4/wheels/bd/34/05/1e3cb4b8f20c20631b411dc5157b4b150850c03496fa96c2c4\n",
            "\u001b[33m  DEPRECATION: Building 'fire' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'fire'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=68789d4d7b2ccda4714ae4aa3b305f643e7d111f097cad9a26314225c2a942e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built llamafactory fire\n",
            "Installing collected packages: shtab, safetensors, pydantic-core, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fire, av, sse-starlette, pydantic, nvidia-cusparse-cu12, nvidia-cudnn-cu12, modelscope, tyro, tokenizers, nvidia-cusolver-cu12, gradio-client, gradio, datasets, accelerate, trl, peft, llamafactory\n",
            "\u001b[2K  Attempting uninstall: safetensors\n",
            "\u001b[2K    Found existing installation: safetensors 0.6.1\n",
            "\u001b[2K    Uninstalling safetensors-0.6.1:\n",
            "\u001b[2K      Successfully uninstalled safetensors-0.6.1\n",
            "\u001b[2K  Attempting uninstall: pydantic-core\n",
            "\u001b[2K    Found existing installation: pydantic_core 2.33.2\n",
            "\u001b[2K    Uninstalling pydantic_core-2.33.2:\n",
            "\u001b[2K      Successfully uninstalled pydantic_core-2.33.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: pydantic\n",
            "\u001b[2K    Found existing installation: pydantic 2.11.7\n",
            "\u001b[2K    Uninstalling pydantic-2.11.7:\n",
            "\u001b[2K      Successfully uninstalled pydantic-2.11.7\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[2K  Attempting uninstall: tokenizers\n",
            "\u001b[2K    Found existing installation: tokenizers 0.21.4\n",
            "\u001b[2K    Uninstalling tokenizers-0.21.4:\n",
            "\u001b[2K      Successfully uninstalled tokenizers-0.21.4\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[2K  Attempting uninstall: gradio-client\n",
            "\u001b[2K    Found existing installation: gradio_client 1.11.0\n",
            "\u001b[2K    Uninstalling gradio_client-1.11.0:\n",
            "\u001b[2K      Successfully uninstalled gradio_client-1.11.0\n",
            "\u001b[2K  Attempting uninstall: gradio\n",
            "\u001b[2K    Found existing installation: gradio 5.41.0\n",
            "\u001b[2K    Uninstalling gradio-5.41.0:\n",
            "\u001b[2K      Successfully uninstalled gradio-5.41.0\n",
            "\u001b[2K  Attempting uninstall: datasets\n",
            "\u001b[2K    Found existing installation: datasets 4.0.0\n",
            "\u001b[2K    Uninstalling datasets-4.0.0:\n",
            "\u001b[2K      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[2K  Attempting uninstall: accelerate\n",
            "\u001b[2K    Found existing installation: accelerate 1.9.0\n",
            "\u001b[2K    Uninstalling accelerate-1.9.0:\n",
            "\u001b[2K      Successfully uninstalled accelerate-1.9.0\n",
            "\u001b[2K  Attempting uninstall: peft\n",
            "\u001b[2K    Found existing installation: peft 0.17.0\n",
            "\u001b[2K    Uninstalling peft-0.17.0:\n",
            "\u001b[2K      Successfully uninstalled peft-0.17.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [llamafactory]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.7.0 av-15.0.0 datasets-3.6.0 fire-0.7.0 gradio-5.31.0 gradio-client-1.10.1 llamafactory-0.9.4.dev0 modelscope-1.28.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 peft-0.15.2 pydantic-2.10.6 pydantic-core-2.27.2 safetensors-0.5.3 shtab-1.7.2 sse-starlette-3.0.2 tokenizers-0.21.1 trl-0.9.6 tyro-0.8.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd LLaMA-Factory && pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqt-8ZkXEfu7",
        "outputId": "6f882ec4-cf35-42f3-f001-00a34145d980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers!=4.52.0,<=4.55.0,>=4.49.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (4.55.0)\n",
            "Requirement already satisfied: datasets<=3.6.0,>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (3.6.0)\n",
            "Requirement already satisfied: accelerate<=1.7.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (1.7.0)\n",
            "Requirement already satisfied: peft<=0.15.2,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.15.2)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.9.6)\n",
            "Requirement already satisfied: tokenizers<=0.21.1,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.21.1)\n",
            "Requirement already satisfied: gradio<=5.31.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (5.31.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (3.10.0)\n",
            "Requirement already satisfied: tyro<0.9.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.8.14)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.8.1)\n",
            "Collecting numpy<2.0.0 (from llamafactory==0.9.4.dev0)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (1.16.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.10.0)\n",
            "Requirement already satisfied: modelscope>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (1.28.2)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.1.9)\n",
            "Requirement already satisfied: safetensors<=0.5.3 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.5.3)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.7.0)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (6.0.2)\n",
            "Requirement already satisfied: pydantic<=2.10.6 in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (2.10.6)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.35.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.116.1)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (3.0.2)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (15.0.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.34.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.12.15)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.10.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.11.1)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.12.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.14.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (2.27.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.1.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.52.0,<=4.55.0,>=4.49.0->llamafactory==0.9.4.dev0) (2024.11.6)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (13.9.4)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.17.0)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (1.7.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.20.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.6.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.31.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate<=1.7.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->llamafactory==0.9.4.dev0) (3.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.3.8)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.22)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Building wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=27930 sha256=bf38fda662489aa597fdd07ea8d0bccc34e0393deae380dc0d557f56c96408c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7xgf_5jk/wheels/bd/34/05/1e3cb4b8f20c20631b411dc5157b4b150850c03496fa96c2c4\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: numpy, llamafactory\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.3.2\n",
            "\u001b[2K    Uninstalling numpy-2.3.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.3.2\n",
            "\u001b[2K  Attempting uninstall: llamafactory\n",
            "\u001b[2K    Found existing installation: llamafactory 0.9.4.dev0\n",
            "\u001b[2K    Uninstalling llamafactory-0.9.4.dev0:\n",
            "\u001b[2K      Successfully uninstalled llamafactory-0.9.4.dev0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [llamafactory]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed llamafactory-0.9.4.dev0 numpy-1.26.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3S-jDbCEgqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "\n",
        "login(token=hf_token)\n"
      ],
      "metadata": {
        "id": "raeZj8ePSvs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP83YlmKWFc5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMK7PHSsYYl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4d2984-2b60-4239-dd01-d93ceae1a1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: json_repair in /usr/local/lib/python3.11/dist-packages (0.49.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install json_repair"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSFkk_Icbvgl"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vP3VkgzXD8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "716b43e5-ec63-4050-e17a-8e1eb63a4ee4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1920314401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_repair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m from .auto_factory import (\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_BaseAutoBackboneClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0m_BaseAutoModelClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2322\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_deepspeed_zero3_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_fsdp_managed_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasking_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_masks_for_generate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCausalLMOutputWithPast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeq2SeqLMOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0misin_mps_friendly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/masking_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_flex_attn_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflex_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_DEFAULT_SPARSE_BLOCK_SIZE\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mflex_default_block_size\u001b[0m  \u001b[0;31m# noqa: N811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflex_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlockMask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_block_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/attention/flex_attention.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace_wrapped_higher_order_op\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformGetItemToIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_higher_order_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflex_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflex_attention\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mflex_attention_hop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_higher_order_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_set_compilation_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalStateGuard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         )\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "\n",
        "import random\n",
        "from pydantic import BaseModel,Field\n",
        "from typing import List,Optional,Literal\n",
        "from datetime import datetime\n",
        "\n",
        "import json_repair\n",
        "from transformers import AutoModelForCausalLM , AutoTokenizer , BitsAndBytesConfig\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/llm_finetuning\"\n",
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "torch_dtype = None\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCwgrQiqFIi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NaUr_7f_aOtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "98RxzcL-aBRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_json(text):\n",
        "  try:\n",
        "    return json_repair.loads(text)\n",
        "  except:\n",
        "    return None"
      ],
      "metadata": {
        "id": "F55yg9aO0Fdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XP-gzzncMdN"
      },
      "source": [
        "# Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvtXeuyEYW1r"
      },
      "outputs": [],
      "source": [
        "story = \"\"\"عاد الحديث بقوة في تونس، خلال الأسابيع القليلة الماضية، عن استقلال السلطة القضائية، وعن العدل في تنفيذ قرارات المحاكم، وعن دولة القانون والمؤسسات، وعن المحاكمة العادلة، وذلك على خلفية الجدل القائم بين الهيئة العليا للانتخابات والمحكمة الإدارية، بشأن قرارات هذه الأخيرة التي ضربت بها الهيئة عرض الحائط \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIgHXLC4dxwE"
      },
      "source": [
        "## Details Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jwupKoYdlsF"
      },
      "outputs": [],
      "source": [
        "# Define allowed entity types\n",
        "EntityType = Literal[\n",
        "    \"person-male\", \"person-female\", \"location\",\n",
        "    \"organization\", \"event\", \"time\", \"artifact\", \"not_specified\",\n",
        "    \"quantity\", \"money\", \"product\", \"law\", \"disease\"\n",
        "]\n",
        "\n",
        "# Define allowed story categories\n",
        "StoryCategory = Literal[\n",
        "    \"Politics\", \"Business\", \"Economy\", \"Technology\", \"Science\",\n",
        "    \"Health\", \"Entertainment\", \"Sports\", \"World\", \"International\",\n",
        "    \"Local\", \"Regional\", \"Education\", \"Environment\", \"Crime & Law\",\n",
        "    \"Travel\", \"Weather\", \"Lifestyle\", \"Culture\", \"Arts\", \"Religion\",\n",
        "    \"Automotive\", \"Food & Cooking\", \"Not specified\"\n",
        "]\n",
        "\n",
        "# Define Entity model with one value and one type\n",
        "class Entity(BaseModel):\n",
        "    entity_value: str = Field(..., description=\"The actual name or value of the entity\")\n",
        "    entity_type: EntityType = Field(..., description=\"Type of the entity (e.g., person, location, etc.)\")\n",
        "\n",
        "# Define the main NewsDetails model\n",
        "class NewsDetails(BaseModel):\n",
        "    story_title: str = Field(..., min_length=5, max_length=300,\n",
        "                             description=\"A fully informative and SEO-optimized title of the story\")\n",
        "\n",
        "    story_keywords: List[str] = Field(..., min_items=1,\n",
        "                                      description=\"Relevant keywords associated with the story\")\n",
        "\n",
        "    story_summary: List[str] = Field(..., min_items=1, max_items=5,\n",
        "                                     description=\"Summarized key points about the story (1 to 5 points)\")\n",
        "\n",
        "    story_categories: StoryCategory = Field(..., description=\"Main category of the news story\")\n",
        "\n",
        "    story_entities: List[Entity] = Field(..., description=\"List of named entities found in the story\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWKe2j6Fq1_-"
      },
      "outputs": [],
      "source": [
        "details_extraction_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\":\"\\n\".join([\n",
        "            \"you are an NLP data parser\",\n",
        "            \"you will be provided by an arabic text associted with a Pydantic scheme\",\n",
        "            \"Generate the output in the same story language.\"\n",
        "            \"You have to extract JSON details from the text according to the Pydantic schema.\"\n",
        "            \"Extract details exactly as mentioned in the text.\"\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\":\"\\n\".join([\n",
        "            \"## story:\",story.strip(),\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",json.dumps(NewsDetails.model_json_schema() , ensure_ascii=False),\n",
        "            \"\",\n",
        "            \"##story Details:\",\n",
        "            \"```json\"\n",
        "\n",
        "        ])\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ehMGguH-SF-"
      },
      "source": [
        "## Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBDkDkYsy11Q"
      },
      "outputs": [],
      "source": [
        "class TranslatedStory(BaseModel):\n",
        "\n",
        "  translate_title: str = Field(...,min_length=5 , max_length=300 , description=\"suggested translated title of news story.\")\n",
        "  translated_content : str = Field(...,min_length=5 , description=\"suggested translated content of news story.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw_ShA-m767e"
      },
      "outputs": [],
      "source": [
        "# Define the target language\n",
        "targeted_language = \"English\"\n",
        "\n",
        "\n",
        "translation_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"You are a professional translator.\",\n",
        "            \"You will be provided with an Arabic text.\",\n",
        "            f\"You have to translate the text into the {targeted_language}.\",\n",
        "            \"Follow the provided Schema to generate a JSON.\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"#story:\",\n",
        "            story.strip(),\n",
        "            \"## Pydantic Details:\",\n",
        "            json.dumps(TranslatedStory.model_json_schema(), ensure_ascii=False, indent=2),\n",
        "            f\"#Targeted Language: {targeted_language}\"\n",
        "        ])\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si9T6ZUXtFM4",
        "outputId": "e91b1ad8-9c68-4026-9e9d-2e6ba61828b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'$defs': {'Entity': {'properties': {'entity_value': {'description': 'The actual name or value of the entity',\n",
              "     'title': 'Entity Value',\n",
              "     'type': 'string'},\n",
              "    'entity_type': {'description': 'Type of the entity (e.g., person, location, etc.)',\n",
              "     'enum': ['person-male',\n",
              "      'person-female',\n",
              "      'location',\n",
              "      'organization',\n",
              "      'event',\n",
              "      'time',\n",
              "      'artifact',\n",
              "      'not_specified',\n",
              "      'quantity',\n",
              "      'money',\n",
              "      'product',\n",
              "      'law',\n",
              "      'disease'],\n",
              "     'title': 'Entity Type',\n",
              "     'type': 'string'}},\n",
              "   'required': ['entity_value', 'entity_type'],\n",
              "   'title': 'Entity',\n",
              "   'type': 'object'}},\n",
              " 'properties': {'story_title': {'description': 'A fully informative and SEO-optimized title of the story',\n",
              "   'maxLength': 300,\n",
              "   'minLength': 5,\n",
              "   'title': 'Story Title',\n",
              "   'type': 'string'},\n",
              "  'story_keywords': {'description': 'Relevant keywords associated with the story',\n",
              "   'items': {'type': 'string'},\n",
              "   'minItems': 1,\n",
              "   'title': 'Story Keywords',\n",
              "   'type': 'array'},\n",
              "  'story_summary': {'description': 'Summarized key points about the story (1 to 5 points)',\n",
              "   'items': {'type': 'string'},\n",
              "   'maxItems': 5,\n",
              "   'minItems': 1,\n",
              "   'title': 'Story Summary',\n",
              "   'type': 'array'},\n",
              "  'story_categories': {'description': 'Main category of the news story',\n",
              "   'enum': ['Politics',\n",
              "    'Business',\n",
              "    'Economy',\n",
              "    'Technology',\n",
              "    'Science',\n",
              "    'Health',\n",
              "    'Entertainment',\n",
              "    'Sports',\n",
              "    'World',\n",
              "    'International',\n",
              "    'Local',\n",
              "    'Regional',\n",
              "    'Education',\n",
              "    'Environment',\n",
              "    'Crime & Law',\n",
              "    'Travel',\n",
              "    'Weather',\n",
              "    'Lifestyle',\n",
              "    'Culture',\n",
              "    'Arts',\n",
              "    'Religion',\n",
              "    'Automotive',\n",
              "    'Food & Cooking',\n",
              "    'Not specified'],\n",
              "   'title': 'Story Categories',\n",
              "   'type': 'string'},\n",
              "  'story_entities': {'description': 'List of named entities found in the story',\n",
              "   'items': {'$ref': '#/$defs/Entity'},\n",
              "   'title': 'Story Entities',\n",
              "   'type': 'array'}},\n",
              " 'required': ['story_title',\n",
              "  'story_keywords',\n",
              "  'story_summary',\n",
              "  'story_categories',\n",
              "  'story_entities'],\n",
              " 'title': 'NewsDetails',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "NewsDetails.model_json_schema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMaAjTl_t51m"
      },
      "source": [
        "#Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "864ecc052d58413a8acc752519e7a47c",
            "90d156ecc9a44085b7190d0b065212ab",
            "eab6e07a210b4b639734c38fecb26dc4",
            "9ef4bd1849d74e9db1f1d653885bd975",
            "b51565f2672b411a9664ad4f1b3b531a",
            "902bfcbe5035452a8d39e07d9584d3e1",
            "1a33c6764cc0449e8217b02318f6c41d",
            "b5626daa64994846b476b7d02554a1d1",
            "f55d96d87ec44ebeba9ce8683df969b8",
            "d8c3c7bab5eb4e888d9eac1709471906",
            "db626773e0fc4e668ab4c45a15d87f36",
            "e9944fd5cd094aa5ad6e30a798be9ad4",
            "b41a047909784a5091d87ded5d058022",
            "d28fb8e5fff64c009000836279006db9",
            "ce0f28777804493e8641491a2e32fb36",
            "60575ff969014494958e352858491ab2",
            "6ba906bf51cd4983b6d3a12971a590de",
            "43aea7b85f9748d997320884c465d328",
            "5e193935ec2743a88b3d6a4462923e62",
            "c457aa6032f54b488e3c32265be37299",
            "d525811d178f4133994e0c438c18efe8",
            "4906a5277ed546099a46e467550dbaa0",
            "f2279bc685f242a8a06f1c21dd67608f",
            "447a9a3bb8774752ad670c44607af2b1",
            "4bc177ccfcd34ca983e5869ab63c65ee",
            "2d9c684cd9184fa0b13528b84bb047cb",
            "eb25870093a3445f8dc8610c06191756",
            "dd5f56e6280b46a3bc20add17092173a",
            "cdde4c9eb4284db3bcbd6df9d0fce9db",
            "413cb8a0796f4079b8b8beb569b21008",
            "b3b86af0e77c4a1fa18f5b06c8b94896",
            "53c02fa480cc49629a209f34f58bd135",
            "dacbbc6d4f1c41d8a5d686ae71653654",
            "afcafae734ac4cb6867ada6b908bf25b",
            "93ed3548aaec4df0a9cc83fe34049786",
            "a661bf16093d4b6cab316d71e1e54ccd",
            "0688737867ca4b3fbbc3d5b1becb2319",
            "32d880c177c54252ac7d39929c8bb9dd",
            "c1d59f47a3144f84a53d12a87f7e0dfe",
            "22c10e01751b487e8af30a7d7663b425",
            "fece776d690b4f089fa0c696e3e91fb9",
            "063767c8625547c39e6f7f29bd169846",
            "e22fbe4086304c01a7ccd4058630aab3",
            "717e5b7d046f47c9875925bd2dc23f7f",
            "d06ef0e1f73a41c2ac9bbe36a7c3e79b",
            "4cd1fee0f5394ab8a8d86906d948ae72",
            "d866a05da1d64761ae5d583c63a5ab64",
            "133ea324a8ff4a468d7316f919c2825d",
            "e284623ee825469a90e0dde68d69af2f",
            "24f4df5bcba7465f93445d4da7eeec52",
            "cf37014fbd5842ea82451b0fe2f1bf9e",
            "5c555c7ee2df42cea26e70a2f7d7f40f",
            "4e9873185d4e427b8ada997fa4bf7fba",
            "ee56791e225c453e97e9a3083c5be31a",
            "90157a71e7114df29a89fb50aef2963d",
            "f2aa58f9d610496e81bdd36592688843",
            "7f887371cee54c0e87a45c11ae5ee46a",
            "bdaf52fd1c7e407fa00f8fc06c6ccead",
            "612b049be5874b8ea37c0038679708f4",
            "d1d0dbe7407f4a8d967de45bed49c33e",
            "1a7252f2a73943c8aeaac9123db557b3",
            "b3c68da166074e70ad196afef1629e0f",
            "08e0120e0ef24241899c589b09515f53",
            "1be8400fbb8349e78b31b9ed6504d882",
            "e21659e428d54797a51f4e4180c459f7",
            "2f2c2ee2187f49d2adca17371aa83f73",
            "f8c44acac89047f49e2726a94ab8128d",
            "e8857c22226a4e75a0661f7e9d07df22",
            "efe913e545a2468fb0861426a9aff987",
            "f390b3745dc14504aa4b371d8a52735b",
            "dd1f273b2ec549fb84abbb3911714bf5",
            "2020ca7713884e5e881ad5f1ebf21192",
            "985b965e0bbb418689339b77de6f2cde",
            "5e179c98210c46739003e7e24160c557",
            "95ff72c7c7ec4368b97bf8b33736cfed",
            "f52ee30aad324ca2b14c4800fc626720",
            "82c0198710a64556a6f573c80c62f696"
          ]
        },
        "id": "tr0SnXEPr8Tr",
        "outputId": "aa651288-be85-40e0-a539-1d92b4bc91a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "864ecc052d58413a8acc752519e7a47c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9944fd5cd094aa5ad6e30a798be9ad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2279bc685f242a8a06f1c21dd67608f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afcafae734ac4cb6867ada6b908bf25b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d06ef0e1f73a41c2ac9bbe36a7c3e79b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2aa58f9d610496e81bdd36592688843"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8c44acac89047f49e2726a94ab8128d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(base_model_id,\n",
        "                                             device_map=\"auto\",\n",
        "                                             torch_dtype=torch_dtype )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUqUExHd-kFO"
      },
      "source": [
        "### Details Exctraction Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyrpfCVausmu"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(details_extraction_messages,tokenize=False,add_generation_prompt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ9PDZRRvKDW",
        "outputId": "52c3da99-73b3-4142-9e9c-1bd386291d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template(details_extraction_messages,tokenize=False,add_generation_prompt=True)\n",
        "\n",
        "\n",
        "model_inputs = tokenizer([text],return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens = 1024,\n",
        "    do_sample = False , top_k = None , temperature = None , top_p= None\n",
        ")\n",
        "\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids ,output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "\n",
        "response  = tokenizer.batch_decode(generated_ids,skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRmxObuxvKfG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehKC1o3Z8MwR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpAsrXgFx4pn",
        "outputId": "ed773a48-b69b-4f8b-84d7-b264870f4400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"story_title\": \"الحديث يعود بقوة في تونس حول استقلال السلطة القضائية ودولة القانون\",\n",
            "  \"story_keywords\": [\n",
            "    \"تونس\",\n",
            "    \"استقلال السلطة القضائية\",\n",
            "    \"عدالة المحاكم\",\n",
            "    \"دولة القانون\",\n",
            "    \"محكمة الإدارية\",\n",
            "    \"هيئة الانتخابات\",\n",
            "    \"المحاكمة العادلة\"\n",
            "  ],\n",
            "  \"story_summary\": [\n",
            "    \"الحديث يعود بقوة في تونس، خلال الأسابيع القليلة الماضية، عن استقلال السلطة القضائية، وعن العدل في تنفيذ قرارات المحاكم، وعن دولة القانون والمؤسسات، وعن المحاكمة العادلة.\",\n",
            "    \"ذلك على خلفية الجدل القائم بين الهيئة العليا للانتخابات والمحكمة الإدارية، بشأن قرارات هذه الأخيرة التي ضربت بها الهيئة عرض الحائط.\"\n",
            "  ],\n",
            "  \"story_categories\": [\n",
            "    \"Politics\",\n",
            "    \"Law\"\n",
            "  ],\n",
            "  \"story_entities\": [\n",
            "    {\n",
            "      \"entity_value\": \"تونس\",\n",
            "      \"entity_type\": \"location\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"استقلال السلطة القضائية\",\n",
            "      \"entity_type\": \"law\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"عدالة المحاكم\",\n",
            "      \"entity_type\": \"law\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"دولة القانون\",\n",
            "      \"entity_type\": \"law\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"محكمة الإدارية\",\n",
            "      \"entity_type\": \"organization\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"هيئة الانتخابات\",\n",
            "      \"entity_type\": \"organization\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"المحاكمة العادلة\",\n",
            "      \"entity_type\": \"law\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMFN__7--rcu"
      },
      "source": [
        "### Translation Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaDveR30-uBi"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(translation_messages,tokenize=False,add_generation_prompt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOadhTwS-uBj"
      },
      "outputs": [],
      "source": [
        "model_inputs = tokenizer([text],return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens = 1024,\n",
        "    do_sample = False , top_k = None , temperature = None , top_p= None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QFSuSw1-uBj"
      },
      "outputs": [],
      "source": [
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids ,output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "\n",
        "response  = tokenizer.batch_decode(generated_ids,skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hZplutv-4oy",
        "outputId": "4d400851-4529-4e4d-f2c6-fb896d3ea993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"translate_title\": \"The Debate on Independent Judiciary and Legal Execution in Tunisia Continues\",\n",
            "  \"translated_content\": \"In recent weeks, discussions about the independence of the judiciary, fair execution of court decisions, rule of law and institutions, and fair trials have been ongoing in Tunisia due to the debate between the High Election Council and the Administrative Court regarding the rulings made by this latter body that disregarded the council's stance.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdNCxKiMzrKq",
        "outputId": "cbdb684a-f051-4d44-e199-a00fcb8497cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljW9gMy9hUjE"
      },
      "source": [
        "# Knowledge Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsEksVPwhT0F"
      },
      "outputs": [],
      "source": [
        "raw_data_path = join(data_dir, \"datasets\",\"news-sample.jsonl\")\n",
        "\n",
        "raw_data = []\n",
        "\n",
        "for line in open(raw_data_path):\n",
        "  if line.strip() == \"\":\n",
        "    continue\n",
        "\n",
        "  raw_data.append(\n",
        "      json.loads(line.strip())\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_ubE9eriLHD"
      },
      "outputs": [],
      "source": [
        "random.Random(2).shuffle(raw_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preparing dataset for finetuning"
      ],
      "metadata": {
        "id": "sYnxKzgjxxTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "huK_-Hcx6QcM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw-RQJOmm7_X"
      },
      "outputs": [],
      "source": [
        "save_to = join(data_dir ,\"datasets\", \"sup_f_t.jsonl\")\n",
        "\n",
        "for story in tqdm(raw_data):\n",
        "  sample_details_extraction_messages = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\":\"\\n\".join([\n",
        "              \"you are an NLP data parser\",\n",
        "              \"you will be provided by an arabic text associted with a Pydantic scheme\",\n",
        "              \"Generate the output in the same story language.\"\n",
        "              \"You have to extract JSON details from the text according to the Pydantic schema.\"\n",
        "              \"Extract details exactly as mentioned in the text.\"\n",
        "              \"Do not generate any introduction or conclusion.\"\n",
        "          ])\n",
        "      },\n",
        "      {\n",
        "          \"role\":\"user\",\n",
        "          \"content\":\"\\n\".join([\n",
        "              \"## story:\",story[\"content\"].strip(),\n",
        "              \"\",\n",
        "\n",
        "              \"## Pydantic Details:\",json.dumps(NewsDetails.model_json_schema() , ensure_ascii=False),\n",
        "              \"\",\n",
        "              \"##story Details:\",\n",
        "              \"```json\"\n",
        "\n",
        "          ])\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  text = tokenizer.apply_chat_template(sample_details_extraction_messages,tokenize=False,add_generation_prompt=True)\n",
        "\n",
        "\n",
        "  model_inputs = tokenizer([text],return_tensors=\"pt\").to(device)\n",
        "\n",
        "  generated_ids = model.generate(\n",
        "      model_inputs.input_ids,\n",
        "      max_new_tokens = 1024,\n",
        "      do_sample = False , top_k = None , temperature = None , top_p= None\n",
        "  )\n",
        "\n",
        "  generated_ids = [\n",
        "      output_ids[len(input_ids):]\n",
        "      for input_ids ,output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "  ]\n",
        "\n",
        "\n",
        "  response_of_data  = tokenizer.batch_decode(generated_ids,skip_special_tokens=True)[0]\n",
        "\n",
        "  llm_response_dict = parse_json(response_of_data)\n",
        "\n",
        "  if not llm_response_dict:\n",
        "    continue\n",
        "  with open(save_to, \"a\", encoding=\"utf-8\") as dest:\n",
        "    dest.write(json.dumps({\n",
        "        \"story\": story[\"content\"].strip(),\n",
        "        \"task\": \"Extract the story details into a JSON.\",\n",
        "        \"output_scheme\":json.dumps(NewsDetails.model_json_schema(),ensure_ascii=False),\n",
        "        \"response\": llm_response_dict,\n",
        "    }, ensure_ascii=False , default = str) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Format finetuning datasets"
      ],
      "metadata": {
        "id": "ePVGhBcE_Zoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sft_data_path = join(data_dir, \"datasets\", \"sft.jsonl\")\n",
        "llm_finetunning_data = []\n",
        "\n",
        "\n",
        "system_message = \"\\n\".join([\n",
        "    \"You are a professional NLP data parser.\" ,\n",
        "    \"Follow the provided 'Task'  by the user and the 'Output Scheme' to generate the 'Output JSON' .\",\n",
        "    \"Do not generate any introduction or conclusion.\"\n",
        "\n",
        "])\n",
        "for line in open (sft_data_path):\n",
        "  if line.strip() == \"\":\n",
        "    continue\n",
        "  rec = json.loads(line.strip())\n",
        "\n",
        "\n",
        "  llm_finetunning_data.append({\n",
        "      \"system\":system_message,\n",
        "      \"instructions\":\"\\n\".join([\n",
        "          \"# Story\",rec[\"story\"],\n",
        "          \"# Task\", rec[\"task\"],\n",
        "          \"# Output Scheme\",\n",
        "          rec[\"output_scheme\"],\n",
        "          \"\",\n",
        "          \"#output JSON: \",\n",
        "          \"```json\"\n",
        "      ]),\n",
        "      \"input\"\n",
        "      \"output\":\"\\n\".join([\n",
        "          \"```json\",\n",
        "          json.dumps(rec[\"response\"],ensure_ascii=False , default=str),\n",
        "          \"```\"\n",
        "      ]),\n",
        "      \"history\":[]\n",
        "  })\n",
        "\n",
        "random.Random(101).shuffle(llm_finetunning_data)"
      ],
      "metadata": {
        "id": "UA3isFWO265d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(llm_finetunning_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRFE7bAODgG3",
        "outputId": "3e4f9138-7376-441b-f150-f91b8023fab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2766"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_size = 2700\n",
        "\n",
        "train_ds = llm_finetunning_data[:train_data_size]\n",
        "\n",
        "eval_ds = llm_finetunning_data[train_data_size:]\n",
        "\n",
        "os.makedirs(join(data_dir, \"datasets\", \"llamafactory-finetune-data\"), exist_ok=True)\n",
        "\n",
        "with open(join(data_dir, \"datasets\", \"llamafactory-finetune-data\",\"train.json\"),\"w\") as dest:\n",
        "  json.dump(train_ds , dest , ensure_ascii=False , default=str)\n",
        "\n",
        "with open(join(data_dir, \"datasets\", \"llamafactory-finetune-data\",\"val.json\"),\"w\") as dest:\n",
        "  json.dump(eval_ds , dest , ensure_ascii=False , default=str)"
      ],
      "metadata": {
        "id": "_gP49aeSD-bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/gdrive/MyDrive/llm_finetuning/datasets/llamafactory-finetune-data/train.json\n",
        "\n",
        "/drive/MyDrive/llm_finetuning/datasets/llamafactory-finetune-data/train.json"
      ],
      "metadata": {
        "id": "Mfca9InkQlkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FineTuning"
      ],
      "metadata": {
        "id": "3jSN1op2I9Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Configure LLaMA-Factory for the new datasets\n",
        "\n",
        "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
        "# ```\n",
        "   \"news_finetune_train\": {\n",
        "        \"file_name\": \"/content/drive/MyDrive/llm_finetuning/datasets/llamafactory-finetune-data/train.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    },\n",
        "    \"news_finetune_val\": {\n",
        "        \"file_name\": \"/content/drive/MyDrive/llm_finetuning/datasets/llamafactory-finetune-data/val.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    }\n",
        "# ```\n"
      ],
      "metadata": {
        "id": "z6VR6NEYGvSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n",
        "\n",
        "### model\n",
        "model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct\n",
        "trust_remote_code: true\n",
        "\n",
        "### method\n",
        "stage: sft\n",
        "do_train: true\n",
        "finetuning_type: lora\n",
        "lora_rank: 64\n",
        "lora_target: all\n",
        "\n",
        "### dataset\n",
        "dataset: news_finetune_train\n",
        "eval_dataset: news_finetune_val\n",
        "template: qwen\n",
        "cutoff_len: 3500\n",
        "# max_samples: 50\n",
        "overwrite_cache: true\n",
        "preprocessing_num_workers: 16\n",
        "\n",
        "\n",
        "### output\n",
        "output_dir: /gdrive/MyDrive/llm_finetuning/models/sft\n",
        "logging_steps: 10\n",
        "save_steps: 500\n",
        "plot_loss: true\n",
        "# overwrite_output_dir: true\n",
        "\n",
        "### train\n",
        "per_device_train_batch_size: 1\n",
        "gradient_accumulation_steps: 4\n",
        "learning_rate: 1.0e-4\n",
        "num_train_epochs: 3.0\n",
        "lr_scheduler_type: cosine\n",
        "warmup_ratio: 0.1\n",
        "bf16: true\n",
        "ddp_timeout: 180000000\n",
        "# resume_from_checkpoint: null\n",
        "\n",
        "### eval\n",
        "# val_size: 0.1\n",
        "per_device_eval_batch_size: 1\n",
        "eval_strategy: steps\n",
        "eval_steps: 100\n",
        "\n",
        "report_to: wandb\n",
        "run_name : news_finetuning-llamafactory\n",
        "\n",
        "push_to_hub: true\n",
        "\n",
        "export_hub_model_id: \"Eslamelreedy/news_analyzer\"\n",
        "\n",
        "hub_private_repo: true\n",
        "\n",
        "hub_strategy: checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS_42tpNIW_D",
        "outputId": "f3b7bb56-99a0-40fd-e748-899d8cea5e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2FTv2DSYEsW",
        "outputId": "3c4f55b4-3ea9-45d0-f851-06f9abc7bac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /gdrive/MyDrive/llm_finetuning/models/sft\n"
      ],
      "metadata": {
        "id": "uDNn-RsdQwms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_qwbOF_YE31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd LLaMA-Factory/ && llamafactory-cli train /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgslBCqLOkXk",
        "outputId": "7bed0e4f-ff04-4c78-a4ee-2739fcb6ff32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-12 01:36:55.378875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754962615.640962    4220 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754962615.711143    4220 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754962616.218536    4220 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754962616.218591    4220 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754962616.218596    4220 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754962616.218603    4220 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-12 01:36:56.272514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[INFO|2025-08-12 01:37:10] llamafactory.hparams.parser:410 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16\n",
            "tokenizer_config.json: 7.30kB [00:00, 26.8MB/s]\n",
            "vocab.json: 2.78MB [00:00, 10.2MB/s]\n",
            "merges.txt: 1.67MB [00:00, 8.48MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 14.5MB/s]\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:13,775 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:13,775 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:13,775 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:13,775 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:13,775 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:13,775 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:13,775 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2336] 2025-08-12 01:37:14,143 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "config.json: 100% 660/660 [00:00<00:00, 4.24MB/s]\n",
            "[INFO|configuration_utils.py:752] 2025-08-12 01:37:15,056 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:817] 2025-08-12 01:37:15,062 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.55.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:15,275 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:15,275 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:15,275 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:15,275 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:15,275 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:15,275 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2067] 2025-08-12 01:37:15,275 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2336] 2025-08-12 01:37:15,777 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|2025-08-12 01:37:15] llamafactory.data.loader:143 >> Loading dataset /content/drive/MyDrive/llm_finetuning/datasets/llamafactory-finetune-data/train.json...\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 2700 examples [00:02, 1047.50 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 2700/2700 [00:01<00:00, 2157.78 examples/s]\n",
            "[INFO|2025-08-12 01:37:26] llamafactory.data.loader:143 >> Loading dataset /content/drive/MyDrive/llm_finetuning/datasets/llamafactory-finetune-data/val.json...\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "WARNING:datasets.builder:Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 66 examples [00:00, 98.00 examples/s]\n",
            "Converting format of dataset (num_proc=16): 100% 66/66 [00:01<00:00, 59.23 examples/s] \n",
            "Running tokenizer on dataset (num_proc=16): 100% 2700/2700 [00:46<00:00, 57.64 examples/s] \n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 271, 2, 15106, 510, 29825, 55334, 126458, 143507, 45577, 5703, 123860, 39423, 20064, 131723, 63237, 125007, 128538, 123877, 126385, 73441, 128416, 39434, 124837, 13325, 59842, 8532, 125192, 124766, 125559, 17166, 132748, 128769, 125766, 124006, 77273, 39434, 132579, 53710, 124267, 124114, 123987, 68785, 129943, 73274, 130527, 74315, 124522, 37524, 27490, 124179, 68238, 65398, 84532, 13, 715, 124766, 124283, 124543, 53479, 124322, 25871, 142734, 126655, 125007, 128305, 123877, 126385, 73441, 39434, 133498, 23364, 132137, 47632, 142734, 68785, 128248, 135638, 53479, 127172, 137499, 123877, 124636, 123890, 73441, 128562, 124006, 53479, 58656, 135430, 68785, 133950, 63415, 126385, 73441, 124265, 127467, 124080, 41593, 124636, 124072, 123904, 123963, 47632, 128405, 124837, 124082, 47632, 13, 715, 128388, 125007, 123877, 126385, 73441, 135087, 73441, 128718, 133020, 132070, 125434, 124514, 124082, 70604, 37524, 127799, 132070, 17166, 124480, 39423, 68785, 124838, 125481, 136510, 47632, 123894, 123860, 124766, 126385, 73441, 12961, 11071, 127476, 126815, 81778, 43635, 132033, 124766, 126385, 73441, 123961, 126019, 73441, 124072, 125916, 123832, 68785, 128416, 128510, 125077, 125709, 124130, 25871, 134017, 17166, 132748, 13, 715, 128827, 142201, 74315, 124522, 123961, 12653, 65398, 84532, 68785, 140880, 130283, 77703, 14558, 124346, 125143, 124226, 126350, 39434, 124104, 72804, 128305, 123877, 126385, 73441, 68785, 128259, 125027, 124009, 129919, 73274, 130151, 125637, 124678, 124476, 13325, 125646, 133843, 23224, 91344, 130519, 20931, 135542, 125701, 13, 715, 124838, 129013, 128443, 68785, 73274, 124464, 123860, 128248, 124793, 129843, 73274, 131744, 124793, 44330, 126924, 125007, 73274, 64604, 8532, 123995, 50243, 92381, 124653, 128248, 124080, 123941, 25871, 135276, 126208, 125215, 25871, 126198, 128754, 126214, 128280, 124220, 126924, 126298, 125007, 140620, 124661, 59842, 8532, 124671, 128248, 77703, 124144, 125011, 128248, 17166, 132748, 129521, 125559, 13, 715, 37524, 123860, 21360, 125313, 126899, 128707, 123862, 125653, 125007, 130616, 124261, 124220, 126924, 63237, 129193, 37524, 125657, 25871, 124665, 129636, 128259, 132338, 128636, 129581, 125490, 125108, 127930, 131351, 73441, 382, 2, 5430, 510, 2610, 614, 311, 14683, 279, 3364, 2213, 1119, 6364, 5815, 448, 264, 2265, 1119, 264, 4718, 382, 2, 9258, 43781, 510, 4913, 13193, 788, 5212, 53242, 6112, 788, 5212, 4684, 788, 330, 50, 53276, 24531, 2265, 315, 279, 3669, 3364, 10465, 330, 60992, 788, 220, 17, 20, 20, 11, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 10869, 497, 330, 1313, 788, 330, 917, 14345, 330, 53242, 7495, 788, 5212, 4684, 788, 330, 81016, 2213, 315, 279, 3669, 3364, 10465, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 8883, 497, 330, 1313, 788, 330, 917, 9207, 2137, 330, 6279, 788, 4383, 53242, 6112, 497, 330, 53242, 7495, 7914, 330, 2102, 788, 330, 81016, 17938, 497, 330, 1313, 788, 330, 1700, 63159, 2, 9258, 4718, 25, 151645, 198, 151644, 77091, 198, 73594, 2236, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 5541, 13874, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "\n",
            "# Story:\n",
            "حذرت مجلة فاينانس تست من أن بعض الأدوية قد تهدد سلامة وأمان القيادة لتسببها في تأخر ردة الفعل، مما يرفع خطر وقوع حادث. \n",
            " وأوضحت المجلة الألمانية أن هذه الأدوية تشمل مسكنات الألم، على سبيل المثال المواد الأفيونية ومنها المورفين، وكذلك أدوية الصداع النصفي والمنومات والمهدئات. \n",
            " كما أن الأدوية النفسية مثل مضادات الاكتئاب ومضادات الذهان، وبعض قطرات العين وأدوية ارتفاع ضغط الدم وأدوية الحساسية والسكري، قد تمثل مشكلة أثناء القيادة. \n",
            " ولتجنب خطر الحوادث، ينبغي عدم قيادة السيارة عند تناول هذه الأدوية، لا سيما عندما يشعر المرء بالدوار والنعاس وضعف التركيز. \n",
            " وبشكل عام، يتعين على أي شخص يتناول أي دواء أن يُلقي نظرة على النشرة الداخلية لمعرفة ما إذا كان هذا الدواء يمكن أن يؤثر سلبا على قدرته على القيادة بأمان. \n",
            " وينبغي أيضا مراعاة أن توفر الدواء من دون وصفة طبية لا يعني أنه ليس له آثار جانبية.\n",
            "\n",
            "# Task:\n",
            "You have to translate the story content into English associated with a title into a JSON.\n",
            "\n",
            "# Output Scheme:\n",
            "{\"properties\": {\"translated_title\": {\"description\": \"Suggested translated title of the news story.\", \"maxLength\": 255, \"minLength\": 5, \"title\": \"Translated Title\", \"type\": \"string\"}, \"translated_content\": {\"description\": \"Translated content of the news story.\", \"minLength\": 5, \"title\": \"Translated Content\", \"type\": \"string\"}}, \"required\": [\"translated_title\", \"translated_content\"], \"title\": \"TranslatedStory\", \"type\": \"object\"}\n",
            "\n",
            "# Output JSON:<|im_end|>\n",
            "<|im_start|>assistant\n",
            "```json{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 5541, 13874, 151645, 198]\n",
            "labels:\n",
            "```json{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}```<|im_end|>\n",
            "\n",
            "Running tokenizer on dataset (num_proc=16): 100% 66/66 [00:15<00:00,  4.31 examples/s]\n",
            "eval example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 271, 2, 15106, 510, 129714, 131801, 27846, 130950, 77273, 39434, 123890, 20064, 68785, 128374, 123877, 136176, 124280, 124172, 125767, 25871, 129744, 73441, 68785, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 68785, 131933, 123894, 129600, 77273, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 5703, 124613, 68785, 131933, 44330, 125138, 130771, 124072, 132970, 68785, 131933, 126453, 128559, 124325, 123894, 65398, 128518, 68785, 129673, 128248, 74315, 124284, 73441, 124012, 129600, 124172, 125591, 126212, 138928, 140765, 125006, 127570, 47632, 124072, 134700, 124058, 125573, 73441, 68785, 133707, 77703, 11071, 124669, 128305, 134515, 128261, 126815, 124011, 14293, 128794, 138928, 43982, 125516, 123961, 123829, 43635, 13, 715, 12961, 133326, 14293, 124080, 125940, 143825, 20064, 73441, 125007, 124058, 127524, 47632, 130771, 73441, 128261, 63415, 125150, 14293, 129387, 68238, 125229, 47632, 126198, 128325, 124437, 125520, 68785, 63237, 128374, 44330, 46586, 58656, 220, 17, 15, 16, 19, 68785, 128416, 27846, 47632, 14293, 130656, 127837, 23364, 125154, 123963, 127837, 128464, 131132, 131037, 127923, 131045, 13, 129828, 130519, 53479, 123941, 73771, 135590, 68785, 128325, 142402, 126409, 47632, 23364, 35038, 124352, 123890, 73441, 139412, 12961, 10176, 125645, 14293, 129225, 125849, 135376, 132351, 68785, 128962, 20064, 126453, 128559, 124325, 123894, 65398, 128518, 37524, 136341, 124006, 132294, 126483, 93543, 124006, 131936, 129200, 84996, 126413, 13, 128478, 125007, 126731, 124330, 14558, 55891, 126931, 138752, 126196, 77703, 131910, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 63415, 129714, 17166, 130076, 128252, 137623, 124265, 124261, 68785, 124766, 141068, 55057, 125696, 130170, 123862, 126513, 133483, 39434, 129989, 27846, 124938, 55057, 125069, 130741, 25871, 128252, 124147, 124284, 68785, 27846, 129600, 127837, 63237, 123894, 125629, 13, 715, 128474, 14293, 126453, 31073, 124325, 124058, 125573, 73441, 124665, 135590, 135377, 128707, 32790, 133955, 125006, 127570, 47632, 124269, 124082, 91344, 73441, 68785, 37524, 124621, 126458, 85153, 126415, 123862, 124138, 128252, 123913, 21360, 124181, 138751, 14558, 68785, 23364, 130353, 73441, 137007, 77703, 11071, 124669, 138928, 128261, 128962, 124687, 129080, 135172, 130995, 77703, 126968, 14558, 124838, 125343, 73771, 47632, 37524, 124642, 73441, 68785, 128388, 37524, 125657, 128349, 125637, 32790, 29825, 123890, 127560, 25871, 68785, 127555, 124009, 50243, 41593, 128471, 131695, 14558, 127837, 77703, 131910, 126453, 31073, 124325, 13, 715, 128641, 124009, 39434, 125169, 124269, 69682, 14558, 128586, 77273, 135275, 124072, 129609, 68785, 124072, 126119, 127221, 133527, 123890, 68785, 93153, 124082, 11798, 95975, 125637, 32790, 133955, 126208, 124703, 124138, 131695, 125358, 124837, 138751, 14558, 86941, 123904, 95975, 125838, 82168, 79820, 123860, 125006, 133063, 77703, 124392, 59842, 125090, 73771, 13325, 68785, 127955, 16157, 73441, 128464, 131651, 68785, 129869, 137204, 56794, 127570, 47632, 141396, 63237, 63415, 124514, 130945, 133205, 124665, 124423, 127837, 128402, 124169, 27490, 127837, 68785, 131813, 77703, 131910, 55891, 126931, 138752, 126502, 125106, 127837, 125006, 131610, 68785, 63237, 128374, 124058, 124363, 39423, 77273, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 13, 715, 128280, 134466, 126214, 128763, 84532, 125275, 127726, 136666, 63415, 124014, 77273, 132745, 130519, 12961, 124126, 35244, 70604, 14558, 82168, 65398, 73274, 57859, 123904, 23364, 129614, 39434, 127809, 124035, 142847, 124072, 124706, 95975, 20064, 124080, 125089, 16157, 68785, 37524, 124438, 131032, 63237, 94957, 132119, 129755, 123904, 14558, 126212, 123894, 125152, 47632, 132793, 128248, 94957, 29825, 32790, 123980, 74315, 124284, 128707, 32790, 29825, 126761, 128577, 56794, 57859, 125559, 85153, 127878, 94957, 125313, 93543, 128307, 128657, 133548, 132674, 86941, 84532, 14558, 132280, 68785, 128523, 129445, 124082, 31073, 129174, 12961, 41593, 125346, 123920, 74315, 124284, 128295, 124388, 70604, 220, 17, 20, 135621, 123978, 124412, 220, 17, 15, 17, 16, 68785, 130117, 123920, 63237, 128773, 53479, 139600, 129249, 131045, 68785, 124072, 127099, 127116, 128883, 130881, 47632, 124072, 124938, 124691, 128261, 12961, 14293, 64604, 73771, 137867, 14293, 56794, 124210, 27490, 127837, 68785, 129833, 73274, 125657, 124006, 74315, 140636, 126543, 77703, 124392, 59842, 125090, 73771, 13325, 27846, 124074, 31382, 124341, 124187, 133642, 124072, 13325, 124514, 47632, 126113, 13, 715, 133431, 12961, 27490, 124706, 23224, 63415, 125718, 21360, 55891, 124035, 129899, 126513, 73771, 94957, 125313, 93543, 23364, 125493, 68785, 126420, 128321, 126815, 11071, 125729, 13, 715, 77703, 131910, 55891, 126931, 138752, 128280, 39434, 125766, 77273, 59842, 95198, 43982, 35038, 10176, 63237, 17166, 124519, 27490, 132070, 143098, 55334, 124511, 68785, 92072, 124144, 14293, 126195, 139589, 77703, 126968, 37524, 142539, 125027, 91344, 73441, 124766, 129895, 70604, 128562, 125362, 47632, 68785, 37524, 141470, 133547, 73441, 77273, 135275, 124072, 129609, 13, 37524, 123978, 37524, 125657, 16157, 27846, 124074, 31382, 124464, 20064, 124636, 131795, 125669, 124863, 124072, 133672, 124641, 56794, 133063, 129814, 134898, 13, 126420, 12961, 129080, 14293, 138928, 27846, 134681, 124006, 128252, 63415, 124405, 25871, 132266, 137024, 140597, 55334, 73441, 68785, 129869, 63415, 129152, 91335, 5703, 93153, 124388, 124421, 128412, 68785, 138827, 23364, 41593, 124405, 123995, 128412, 68785, 37524, 11798, 130030, 134035, 92072, 126413, 133612, 65398, 128261, 43982, 64604, 126780, 14293, 128794, 138928, 129185, 85153, 124983, 98719, 129445, 50243, 20064, 35244, 25871, 129431, 77273, 128586, 220, 17, 15, 16, 16, 68785, 27846, 134736, 129445, 12961, 124126, 35244, 70604, 47632, 39434, 130910, 73441, 68238, 127347, 73441, 77273, 133483, 68785, 85153, 21360, 73771, 39423, 125069, 125520, 220, 16, 19, 134340, 124703, 123890, 130277, 220, 17, 15, 16, 16, 13, 715, 12961, 136204, 53479, 124668, 43635, 133527, 124072, 126123, 123938, 39434, 127923, 127837, 63237, 138928, 128577, 56794, 57859, 125559, 52157, 20931, 133176, 138752, 37524, 130163, 124642, 128412, 68785, 128762, 128305, 134515, 63415, 124148, 14293, 128248, 138990, 124006, 13, 37524, 129883, 128755, 124006, 68785, 45577, 35038, 124085, 27846, 124179, 126023, 68785, 125502, 127207, 23364, 136596, 127837, 93153, 124122, 35038, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 131268, 65398, 124220, 5703, 135063, 68785, 128562, 127188, 125572, 124104, 133065, 68785, 37524, 136961, 124478, 43635, 124394, 53479, 124811, 13, 37524, 127029, 12961, 125011, 49388, 127837, 128883, 128074, 124325, 124058, 125573, 73441, 27846, 124343, 27490, 124058, 124328, 98719, 47632, 130771, 73441, 68785, 124209, 135425, 128307, 50243, 20931, 125011, 126453, 31073, 124325, 50243, 124636, 127837, 77703, 124330, 23224, 127837, 68785, 129353, 43982, 125516, 37524, 84532, 125955, 39434, 132596, 59842, 8532, 125192, 85153, 124328, 98719, 130377, 37524, 124938, 124691, 124006, 37524, 129152, 127837, 125006, 130718, 128405, 124322, 25871, 141912, 126510, 125088, 92381, 124325, 56794, 125523, 126453, 31073, 124325, 128402, 124944, 47632, 39434, 129955, 124006, 13, 715, 128641, 129163, 126556, 128546, 124042, 124325, 63237, 128280, 17166, 137378, 124080, 126409, 124082, 68785, 56794, 33090, 127477, 128538, 123877, 124522, 95975, 77273, 133483, 128252, 127115, 124420, 125653, 55891, 126931, 138752, 68785, 82611, 124675, 124422, 124006, 39434, 124423, 73771, 131922, 39434, 129422, 124412, 137024, 68785, 130444, 39434, 125267, 27846, 124621, 124669, 124012, 128026, 140425, 130462, 126453, 31073, 52704, 73771, 124325, 77273, 137637, 138751, 73441, 68785, 129308, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128261, 138073, 73771, 63415, 128074, 49388, 124006, 27846, 47632, 73771, 25871, 37524, 124647, 126510, 68785, 124793, 128478, 77703, 127415, 25871, 125006, 43635, 127206, 128264, 124058, 130353, 98719, 68785, 37524, 129152, 45577, 132412, 98719, 130771, 124072, 135617, 25871, 124058, 125573, 126319, 68785, 128718, 124172, 124420, 14558, 124058, 125573, 14558, 129200, 127818, 131118, 92072, 127602, 68785, 128307, 53710, 124898, 27846, 129345, 16157, 44330, 23224, 125187, 134541, 126510, 130160, 138928, 68785, 27846, 131271, 16157, 142685, 124723, 127837, 50243, 5703, 125940, 127837, 68785, 132402, 27846, 125657, 125011, 142887, 126510, 13, 715, 128671, 141183, 126453, 31073, 124325, 124058, 125573, 73441, 128261, 63415, 64604, 124983, 137648, 128586, 220, 16, 24, 22, 17, 129458, 142641, 77273, 142001, 17166, 125664, 73771, 77273, 44330, 125072, 125187, 39434, 129422, 124412, 137024, 68785, 128261, 129106, 53710, 124898, 124006, 131425, 130353, 98719, 23364, 124621, 125815, 85153, 125573, 73441, 68785, 128474, 125007, 129106, 126731, 127616, 124172, 126277, 123860, 125088, 92381, 124325, 129046, 128443, 220, 17, 15, 16, 19, 68785, 27846, 47632, 33090, 124642, 85153, 125629, 70604, 124006, 23364, 125930, 127837, 63237, 126455, 124388, 125756, 68785, 128562, 29825, 124006, 123894, 125123, 73441, 77273, 77703, 11071, 124669, 124006, 68785, 74315, 41593, 125155, 127837, 77273, 124080, 39697, 123862, 47632, 138751, 73441, 68785, 129869, 137204, 129046, 132371, 73441, 128248, 127072, 35038, 138751, 14558, 73771, 13, 715, 128478, 125007, 55891, 126931, 138752, 53710, 127477, 74315, 125395, 128349, 138787, 127837, 13, 129828, 128707, 73771, 81778, 14293, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 77273, 94957, 127106, 68785, 37524, 126666, 14293, 129431, 128420, 124130, 127837, 134933, 53710, 128722, 68785, 23364, 123987, 124282, 12961, 124543, 126900, 124006, 132371, 73441, 128248, 138752, 37524, 124223, 124669, 124006, 136973, 68785, 63237, 85153, 123987, 39423, 130570, 124006, 128252, 124058, 123987, 39423, 126195, 50243, 14293, 123829, 33090, 124006, 124080, 16157, 126510, 13, 715, 126731, 124466, 55891, 126931, 138752, 126196, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 73274, 126624, 133483, 128252, 137623, 124265, 124261, 68785, 129943, 63415, 127930, 23364, 35244, 5703, 124387, 128967, 93153, 124388, 31382, 124172, 127288, 37524, 130163, 124642, 25871, 137637, 138751, 73441, 715, 37524, 11071, 126106, 124012, 129600, 128307, 126208, 73274, 138210, 52704, 128252, 129968, 126212, 127647, 20064, 46586, 123860, 68785, 128843, 124080, 124787, 125168, 131205, 68785, 129308, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 68785, 131795, 140478, 128248, 127560, 14558, 53479, 127207, 129185, 17166, 135911, 73441, 126543, 77703, 124392, 59842, 125090, 73771, 13325, 68785, 126857, 16157, 93543, 53479, 81778, 130010, 124623, 126418, 123860, 128443, 68238, 126703, 129839, 68785, 132525, 124075, 128862, 125572, 125291, 128755, 68238, 126703, 43982, 124641, 131482, 128307, 63415, 64604, 129955, 123913, 126336, 23364, 124085, 124387, 127837, 128577, 130153, 82168, 11071, 125591, 39434, 13325, 127300, 94957, 39697, 124811, 47632, 129839, 73441, 68785, 68238, 124125, 12961, 125011, 49388, 137024, 125490, 13, 715, 129581, 128280, 37524, 129523, 68785, 126420, 59842, 35038, 124675, 137024, 140597, 55334, 73441, 128252, 50243, 123941, 77703, 131910, 138928, 131695, 124012, 123832, 124267, 124269, 124131, 73441, 125006, 135463, 143825, 20064, 73441, 128577, 56794, 130389, 132866, 130063, 124793, 63415, 124014, 77273, 123894, 69423, 25871, 128252, 17166, 58656, 98719, 68785, 128388, 73274, 11071, 124848, 126543, 59842, 125090, 73771, 13325, 136075, 127837, 13, 715, 126420, 128342, 137024, 68785, 23364, 31073, 124126, 55891, 126931, 138752, 63237, 52157, 29825, 124282, 123961, 83827, 138751, 14558, 68785, 129271, 124811, 91344, 125700, 123904, 25871, 68785, 130245, 129521, 58656, 124181, 17166, 124181, 124015, 123862, 68785, 77273, 139268, 23364, 129806, 134470, 137410, 68785, 126513, 130656, 125637, 32790, 133955, 127560, 25871, 129174, 63415, 124148, 14293, 138928, 128248, 85153, 20064, 27490, 124330, 39434, 129104, 29825, 124138, 125006, 127570, 47632, 124269, 124082, 91344, 73441, 128416, 68238, 64604, 124131, 128953, 128259, 53710, 33090, 124511, 128985, 68785, 129265, 74315, 125633, 55891, 126931, 138752, 126214, 59842, 125260, 127837, 128562, 43635, 123995, 127837, 68785, 77273, 133114, 125237, 137024, 13, 715, 124072, 132777, 68785, 134436, 128305, 53479, 124653, 130528, 128261, 129106, 128857, 53710, 124851, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 13, 129828, 59842, 125173, 56794, 133501, 123894, 129600, 125007, 53710, 124851, 14293, 128264, 39434, 81778, 124420, 14293, 126195, 129458, 124636, 55334, 68238, 124613, 126453, 31073, 124325, 124058, 125573, 73441, 130394, 125106, 31382, 77703, 131910, 85153, 23224, 132157, 124172, 125259, 25871, 220, 19, 24, 63237, 63415, 124224, 220, 20, 22, 77703, 124420, 14558, 127837, 68785, 128307, 12961, 14293, 64604, 73771, 137867, 128763, 133810, 130656, 53710, 124082, 125309, 77273, 135333, 129895, 129194, 220, 17, 15, 17, 17, 13, 715, 126208, 39434, 124232, 69682, 131209, 123894, 129600, 27846, 130076, 55891, 124035, 129899, 124172, 125259, 25871, 68785, 128523, 128325, 44330, 35244, 72804, 124138, 77273, 85153, 125248, 70604, 37524, 29825, 128862, 73771, 126195, 140591, 93153, 124122, 73771, 56794, 124079, 25871, 133674, 68785, 130444, 39434, 8532, 124880, 14293, 128252, 77703, 131910, 126453, 31073, 124325, 124058, 125573, 73441, 13, 126420, 123877, 91335, 55057, 63237, 128349, 68785, 125007, 55891, 124035, 129899, 124172, 125259, 25871, 126198, 73274, 130234, 123890, 128523, 128438, 134689, 23364, 139191, 47632, 134541, 126510, 63237, 128474, 137024, 68785, 56794, 130110, 49388, 124138, 126436, 11798, 73771, 85153, 125248, 70604, 37524, 124464, 43635, 95198, 23364, 126780, 27490, 85153, 125573, 14558, 131268, 123963, 14558, 135172, 130995, 126906, 13, 715, 128523, 125088, 125362, 47632, 136355, 128261, 39434, 39697, 124423, 44330, 126119, 124006, 126195, 130771, 124072, 127614, 126212, 138355, 68785, 128248, 125040, 131910, 131534, 128586, 143826, 125006, 138391, 125088, 92381, 124325, 132474, 70604, 73441, 123877, 124273, 27490, 77273, 39434, 123890, 20064, 68785, 53710, 124851, 14293, 124058, 55334, 134056, 56794, 129305, 126453, 31073, 124325, 124058, 125573, 73441, 142740, 128474, 27846, 57859, 124511, 128962, 70604, 124280, 68785, 56794, 126692, 29825, 128707, 124937, 53710, 27490, 125275, 126208, 127809, 124290, 124114, 20064, 65398, 68785, 128307, 128657, 39697, 124423, 16157, 125637, 32790, 29825, 56794, 11071, 124082, 91344, 25871, 140779, 126113, 68785, 131268, 65398, 124220, 5703, 135063, 13, 715, 130267, 126198, 126731, 124404, 130622, 126453, 31073, 124325, 124058, 125573, 73441, 129185, 43982, 136692, 13, 131649, 128342, 124478, 128655, 124678, 136709, 59842, 125750, 128402, 141905, 68785, 128762, 17166, 124210, 125492, 49388, 128252, 77703, 11071, 124669, 124006, 124766, 128074, 49388, 124006, 77273, 45577, 57859, 73771, 124080, 39697, 123862, 47632, 68785, 126198, 73274, 130234, 126815, 23224, 124394, 127837, 68785, 128342, 126208, 50243, 124388, 63237, 124079, 10176, 127837, 13, 130267, 126198, 73274, 134224, 59842, 124035, 31382, 127837, 82168, 129094, 123832, 127837, 128967, 63415, 124125, 70604, 37524, 126385, 123862, 14558, 130283, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128248, 139066, 63237, 128288, 124265, 80970, 124668, 47632, 128261, 23364, 64604, 11798, 124543, 129046, 13, 715, 77273, 76841, 91344, 25871, 130226, 73441, 77703, 126968, 73441, 50243, 64604, 123941, 14293, 133427, 124343, 127837, 128967, 129458, 124636, 55334, 63415, 128074, 49388, 37524, 124621, 124669, 124172, 127288, 124058, 125573, 14558, 77273, 39434, 123890, 20064, 68785, 63415, 124347, 124172, 124420, 14558, 124058, 125573, 14558, 68785, 131268, 65398, 125110, 70604, 123832, 68785, 128252, 126198, 128962, 124009, 124006, 39434, 133172, 10176, 8803, 116, 127706, 130283, 129458, 124636, 55334, 63415, 128074, 49388, 124172, 127288, 124058, 125573, 14558, 68785, 128523, 133455, 73274, 64604, 11798, 124675, 124476, 133812, 128307, 128259, 39434, 64604, 139178, 63415, 128074, 49388, 16157, 37524, 124621, 124669, 16157, 68785, 129308, 124012, 124014, 25871, 128261, 39434, 141707, 77273, 133474, 128248, 128858, 123877, 130211, 11798, 77273, 39434, 123890, 20064, 68785, 86941, 135328, 25871, 130759, 128248, 128305, 124478, 49388, 127472, 125653, 128261, 39434, 131377, 128794, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 496, 56794, 49388, 127472, 125653, 39434, 125704, 128438, 126492, 125267, 124172, 127288, 124058, 125573, 14558, 128248, 86941, 20931, 73771, 43982, 52704, 20931, 123832, 14293, 13, 715, 126208, 73274, 138210, 52704, 132474, 126409, 126350, 130283, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128342, 124009, 138073, 73771, 124642, 125502, 133498, 23364, 134363, 25871, 132371, 73441, 128248, 127072, 35038, 138751, 14558, 68785, 37524, 124438, 39434, 124223, 31073, 126453, 31073, 124325, 129521, 29825, 123995, 128412, 130771, 73441, 128248, 128280, 130208, 13, 128762, 55891, 126931, 138752, 128671, 128416, 59842, 125173, 14293, 136656, 128252, 128349, 129185, 17166, 135911, 73441, 68785, 63237, 128374, 85153, 123987, 39423, 128464, 133624, 124476, 31073, 124466, 128248, 137637, 138751, 73441, 13, 715, 137687, 53479, 124062, 124267, 56794, 11071, 130025, 125192, 138752, 68785, 129308, 63237, 39434, 131731, 130570, 128587, 17166, 124181, 124015, 123862, 68785, 129308, 63237, 39434, 133033, 128248, 130759, 94957, 41593, 124623, 14293, 68785, 128562, 39434, 127207, 126195, 50243, 14293, 123829, 124649, 124080, 16157, 126510, 13, 126857, 65398, 14293, 128248, 128349, 68785, 126513, 131694, 43635, 14293, 129225, 124434, 124006, 126906, 132371, 73441, 128248, 132919, 124072, 132970, 132919, 73441, 68785, 126420, 128523, 128248, 138324, 132919, 73441, 125637, 32790, 124290, 125006, 134971, 73771, 68785, 131247, 126198, 73274, 64604, 124676, 77273, 128538, 125088, 136077, 132919, 73441, 68785, 74315, 41593, 125155, 127837, 17166, 124519, 27490, 132070, 128261, 39434, 124146, 73771, 16157, 128252, 138928, 13, 715, 129581, 128280, 37524, 129523, 68785, 126420, 128342, 55891, 126931, 138752, 63415, 123987, 124126, 128464, 133624, 128248, 23364, 124347, 124571, 125088, 125362, 47632, 53479, 124233, 126987, 77273, 23364, 123940, 124572, 25871, 138752, 68785, 128718, 63237, 125362, 14293, 27910, 14558, 132823, 73274, 27490, 92381, 128402, 123940, 124572, 123890, 68785, 37524, 132621, 125011, 124009, 124476, 124434, 65398, 53479, 124421, 68785, 125449, 98719, 124376, 128248, 126198, 77703, 125962, 128342, 124006, 85153, 126123, 124669, 63237, 141405, 124269, 124131, 73441, 27846, 134440, 128920, 128248, 39434, 124453, 95198, 63415, 126336, 123938, 13, 128280, 132338, 125007, 138928, 93153, 125849, 55334, 14293, 128523, 128248, 129366, 124172, 127288, 68785, 53479, 35244, 72804, 37524, 29825, 91335, 27846, 137321, 128264, 50243, 124636, 39434, 124138, 25871, 124114, 20064, 65398, 53479, 124421, 128248, 125088, 125362, 128885, 13, 715, 128280, 124080, 39697, 124179, 125006, 126992, 123904, 25871, 128248, 137637, 138751, 73441, 68785, 132178, 124876, 65398, 126453, 31073, 124325, 124058, 125573, 73441, 63237, 131132, 47632, 136837, 138065, 124006, 125088, 41593, 125155, 129387, 77703, 126968, 127837, 77273, 140691, 124476, 127570, 47632, 68785, 82168, 130362, 130684, 63237, 131997, 98719, 124766, 20064, 47632, 55334, 25871, 130771, 73274, 129883, 123890, 126195, 92072, 126406, 124138, 68785, 128306, 124232, 73771, 132280, 126195, 53710, 124851, 124138, 128349, 27846, 124283, 128722, 13, 715, 129828, 12961, 126020, 123877, 46586, 125908, 86941, 125291, 125449, 23364, 20064, 124915, 68785, 128631, 127564, 77273, 124172, 127288, 124058, 125573, 14558, 68785, 125007, 126453, 31073, 124325, 124058, 125573, 73441, 39434, 137427, 124476, 126897, 73441, 140286, 25871, 128248, 138752, 68785, 74315, 41593, 125155, 127837, 77273, 124080, 39697, 123862, 47632, 138751, 73441, 129271, 128074, 49388, 142887, 126510, 126249, 47632, 73771, 25871, 124265, 65398, 124653, 134035, 68785, 128660, 126198, 63415, 31073, 91335, 128912, 63237, 53479, 138611, 123860, 77273, 130771, 124220, 46586, 125729, 68785, 77273, 142011, 50243, 64604, 123941, 138147, 125088, 138473, 77273, 133407, 63237, 136077, 85153, 126010, 73441, 39434, 123890, 20064, 73441, 124766, 33090, 125197, 73441, 13, 715, 128259, 73274, 125638, 124148, 143331, 128248, 132371, 73441, 128248, 138752, 68785, 128264, 128248, 131865, 25871, 124172, 127288, 124058, 125573, 14558, 68785, 128264, 128248, 131132, 47632, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 13, 45577, 133299, 128420, 124209, 124328, 25871, 128261, 134684, 124636, 125110, 125275, 68785, 128388, 73274, 124676, 13, 130208, 137961, 27846, 124985, 124130, 25871, 125027, 91344, 73441, 77273, 123894, 124992, 68785, 39434, 137402, 127586, 11071, 124346, 132793, 77273, 126453, 5703, 124613, 47632, 123894, 65398, 128518, 68785, 37524, 126666, 124172, 127288, 128321, 124114, 14558, 124224, 77273, 124080, 39697, 123862, 47632, 126212, 137024, 37524, 124446, 123963, 124006, 68785, 37524, 123997, 127347, 93153, 124388, 31382, 127647, 20064, 124966, 142887, 126510, 68785, 37524, 57859, 125559, 23364, 129614, 124114, 124224, 126212, 141405, 68785, 37524, 132212, 143056, 53479, 125837, 73441, 124072, 127393, 73441, 68785, 134018, 123832, 47632, 27846, 131610, 128510, 129198, 130377, 13, 715, 128280, 126198, 126731, 125629, 16157, 143385, 31073, 123961, 127347, 73441, 128438, 68785, 128261, 140260, 125007, 136930, 126453, 31073, 124325, 124058, 125573, 73441, 129581, 140545, 82168, 39697, 124678, 63237, 128288, 68785, 128248, 53710, 69682, 14558, 136719, 127087, 136079, 98719, 13, 715, 128342, 130208, 137961, 125449, 39697, 124179, 137024, 140597, 55334, 73441, 130570, 14558, 127837, 37524, 137355, 127837, 128252, 125100, 138648, 25871, 128248, 127647, 20064, 124966, 142887, 126510, 128953, 128443, 13, 45577, 138023, 50243, 32790, 69682, 25871, 124172, 127288, 77273, 39434, 123890, 20064, 77273, 134259, 74315, 124223, 123860, 125013, 135640, 129745, 68785, 128660, 126502, 125229, 126420, 128098, 124209, 13325, 124072, 33090, 55334, 21360, 126196, 137024, 123961, 128559, 124325, 68785, 128261, 50243, 39697, 124675, 129353, 132450, 143826, 131801, 124072, 124363, 130142, 128252, 125100, 138648, 25871, 128248, 125637, 129152, 142887, 124863, 37524, 123993, 126751, 93153, 124388, 124421, 125011, 13, 138829, 124678, 127837, 27846, 130400, 126543, 17166, 123940, 124552, 123961, 132261, 27846, 58656, 123995, 128617, 68785, 128476, 126214, 73274, 124131, 55057, 77703, 127288, 125572, 23224, 124176, 68785, 128707, 58656, 127837, 27846, 20931, 127552, 68238, 73594, 2236, 4913, 26485, 6112, 788, 330, 31382, 125510, 8532, 128967, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 37524, 133877, 16157, 128248, 138752, 497, 330, 26485, 51354, 788, 4383, 135564, 20064, 497, 330, 31382, 123993, 124917, 142887, 126510, 497, 330, 31382, 127570, 47632, 497, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 31382, 134700, 124058, 125573, 73441, 7914, 330, 26485, 27251, 788, 4383, 14293, 130010, 123980, 131801, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 10465, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 39434, 131377, 12961, 124126, 27490, 132070, 130153, 85153, 125669, 98719, 128707, 32790, 133955, 10465, 330, 31382, 134700, 124058, 125573, 73441, 39434, 125267, 124665, 135590, 125637, 32790, 133955, 37524, 124464, 14558, 91335, 10176, 125006, 124125, 124181, 138751, 14558, 10465, 330, 31382, 123993, 124917, 140597, 55334, 73441, 39434, 64604, 129080, 124476, 126992, 123904, 25871, 128248, 124172, 127288, 10465, 330, 124341, 43635, 80970, 23224, 47632, 124269, 69682, 14558, 39434, 129198, 39434, 127923, 52157, 124232, 73441, 126543, 59842, 125090, 73771, 13325, 1189, 1125, 330, 26485, 11847, 788, 330, 9896, 46979, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 135564, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 127521, 124085, 27846, 124179, 126023, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 124423, 65398, 124220, 5703, 135063, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 123904, 127188, 125572, 124104, 133065, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 136961, 124478, 43635, 124394, 53479, 124811, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 31382, 134700, 124058, 125573, 73441, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 127137, 128586, 143826, 125006, 138391, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 84532, 125520, 220, 16, 19, 134340, 497, 330, 2996, 1819, 788, 330, 3087, 9207, 60, 5541, 13874, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "\n",
            "# Story:\n",
            "عاد الحديث بقوة في تونس، خلال الأسابيع القليلة الماضية، عن استقلال السلطة القضائية، وعن العدل في تنفيذ قرارات المحاكم، وعن دولة القانون والمؤسسات، وعن المحاكمة العادلة، وذلك على خلفية الجدل القائم بين الهيئة العليا للانتخابات والمحكمة الإدارية، بشأن قرارات هذه الأخيرة التي ضربت بها الهيئة عرض الحائط. \n",
            " اعتقدت النخب التونسية أن الإصلاحات القانونية التي أقدمت عليها حكومات ما بعد الثورة، من خلال دستور 2014، قد باتت أمرًا محسومًا ولا مجال للتراجع عنه. فقد وضع المشرّعون، بعد نقاشات ماراثونية طويلة امتدت لنحو ثلاث سنوات، أسس المحاكمة العادلة وشروطها ومعاييرها الدولية المعروفة. غير أن تعاطي هيئة الانتخابات مع قرار المحكمة الإدارية، أعاد الوضع إلى نقطة الصفر، وأعطى الانطباع بأن البلاد تسير بخطى ثابتة إلى الخلف، بدلًا من العكس. \n",
            " قبلت المحكمة الإدارية طعون ثلاثة مرشحين للانتخابات الرئاسية، وقررت إرجاعهم إلى السباق الانتخابي، ملغية بذلك قرارات الهيئة التي أسقطتهم بدون وجه قانوني وبتعلّات واهية، كما وصف ذلك المرشحون الثلاثة، وكما نص عليه ضمنيًا قرار المحكمة. \n",
            " وفيما توقع الرأي العام في الداخل والخارج، والفاعلون السياسيون، استئناف المرشحين لمكانهم ضمن المشهد الانتخابي كمنافسين جديين للرئيس قيس سعيّد، المنتهية ولايته، بما يجعل لانتخابات السادس من أكتوبر المقبل طعمًا ومذاقًا، جاء قرار هيئة الانتخابات محبطًا للجميع، من خلال الإمعان في إقصاء المرشحين الثلاثة. \n",
            " هذا القرار كان بمثابة بصيص أمل في تحقيق وضع انتخابي جاد يضمن مبدأ تكافؤ الفرص والتنافس النزيه، وسط حالة من التوافق الضمني بين العائلات السياسية على التحشيد خلف مرشح واحد؛ لضمان إحداث التغيير الذي يتطلع إليه كثيرون، حتى أولئك الذين اصطفوا خلف انقلاب 25 يوليوتموز 2021، وكانوا من أكثر المدافعين عنه، والمبررين للممارسات والخطوات التي اتُّخذت لاحقًا، والتي يصفها خصوم الرئيس قيس سعيّد بـالاستبدادية والدكتاتورية. \n",
            " لقد اقتنع أغلب هؤلاء بأنّ التغيير ممكن، بل هو ضروري. \n",
            " قرار هيئة الانتخابات هذا تسبب في سيل عارم من الانتقادات اللاذعة، صدرت عن رجال قانون وشخصيات سياسية وأحزاب ومنظمات، وفعاليات حقوقية في الداخل والخارج. وتم وصفه بـالتعسفي والإقصائي والمنحاز لرئيس الدولة الحالي. بل اتهمت الهيئة بتحولها إلى أداة لدى السلطة التنفيذية، بما أفقدها استقلاليتها، وبالتالي مصداقيتها، ونزع عنها صفة الحياد التي عُرفت بها الهيئة منذ إنشاء أول نسخة منها في العام 2011، بمناسبة أول انتخابات تعددية حقيقية في البلاد، إبّان ثورة 14 ينايركانون الثاني 2011. \n",
            " انتظر المحيط السياسي والشعبي تراجعًا من الهيئة؛ لضمان شفافية الانتخابات ونزاهتها، لكن هذه الأخيرة أصرت على موقفها. وخرج رئيسها، فاروق بوعسكر، ليعلن مجددًا استمرار إقصاء المرشحين الثلاثة عماد الدايمي، ومنذر الزنايدي، وعبد اللطيف المكي. ووجه اتهامًا للمحكمة الإدارية بخرق الإجراءات القانونية، الشيء الذي نفته المحكمة نفيًا قاطعًا، عبر عرض وثائق تؤكد سلامة إجراءاتها وخطواتها وفقًا للقانون والمجلة الجزائية المنظمة لعمل المحكمة ومجالات تدخلها. \n",
            " وفي خطوة متقدمة من هذا الصراع الناشئ، لجأت بعض الأطراف في البلاد إلى مقاضاة هيئة الانتخابات، باعتبارها تعمّدت تجاوز السلطة، ولم تقبل بقرارات الجهة الوحيدة المحكِّمة في العملية الانتخابية، وهي المحكمة الإدارية، التي تعدّ أحكامها باتّة ونهائية، أي غير قابلة للطعن أو الإلغاء، وفق فقهاء القانون والقضاة الإداريين، مثل القاضي الإداري المعروف أحمد صواب، الذي رفع بدوره دعوى قضائية ضد الهيئة، بوصفه مواطنًا ناخبًا، وليس بصفته القضائية. \n",
            " كانت مهمة المحكمة الإدارية التي أُنشئت العام 1972 تنحصر في مجرد البتّ في دعاوى تجاوز السلطة، التي يتم رفعها لإلغاء مقررات إدارية، قبل أن يتم تعديل القوانين المنظمة لها عام 2014، باتجاه إكسابها مزيدًا من الاستقلالية، ومنحها العلوية في قراراتها، خصوصًا في النزاعات الانتخابية، بما يجعل لها الولاية على المسار الانتخابيّ. \n",
            " غير أن هيئة الانتخابات رأت خلاف ذلك تمامًا. فقد مرّغت قرارات المحكمة الإدارية في التراب، وجعلت منها هيكلًا بلا روح، معلنة احتكارها الولاية على الانتخابات ومساراتها المختلفة، من إعلان تاريخها إلى الإعلان عن نتائجها النهائية. \n",
            " تعامل هيئة الانتخابات مع قرارات المحكمة الإدارية يعيد البلاد إلى نقطة الصفر، مما أثار مخاوف حول استقلال القضاء ونزاهة العملية الانتخابية \n",
            " ورغم الجدل الذي لم ينتهِ إلى الآن بين المؤسستين، فإن النتيجة واحدة، وهي إقصاء المرشحين الثلاثة، والإبقاء على الثلاثي المعلن منذ البداية الرئيس قيس سعيّد، وزهير المغزاوي أمين عام حركة الشعب، والعياشي الزمال رئيس حركة عازمون الذي أُدخل السجن موقوفًا؛ بسبب جرائم تدليس التزكيات الشعبية، حسب اتهام السلطة له. \n",
            " ليس هذا وحسب، بل سارعت السلطة التنفيذية إلى نشر قرار الهيئة ضمن الجريدة الرسمية للجمهورية التونسية؛ لقطع الطريق أمام أي أمل في العودة إلى الوراء، كما يردد الرئيس سعيّد دائمًا. \n",
            " بل إن السلطة، مكنت هيئة الانتخابات من شحنة الحبر الانتخابي، والأكياس الآمنة، الخاصة بأوراق الاقتراع، في رسالة مضمونة الوصول، بأن أمر المرشحين الثلاثة الذين أصرت الهيئة على إسقاط ترشحهم للانتخابات الرئاسية قد حُسم بشكل لا رجعة فيه، وأن خيار هيئة الانتخابات كان سليمًا ومنطقيًا، في تقدير السلطة. \n",
            " والحقيقة، ليست هذه المرة الأولى التي يتم فيها رفض تنفيذ قرارات المحكمة الإدارية. فقد سبق لوزارة العدل أن رفضت أو تغاضت عن تنفيذ حكم المحكمة الإدارية بإبطال قرار إعفاء القضاة 49 من أصل 57 قاضيًا، الذي اتُّخذ بموجب أمر رئاسي في يونيوحزيران 2022. \n",
            " لم تعبأ وزارة العدل بوضع هؤلاء القضاة، حتى بعد دخولهم في إضراب وحشيّ عن الطعام استمرّ لعدة أيام، ولم تلتفت إلى قرار المحكمة الإدارية. بل الأدهى من ذلك، أن هؤلاء القضاة ما يزالون حتى اليوم محل ملاحقات قضائية من قبل السلطة، لاتهامهم بشنّ إضراب وتعطيل مرفق إداري عمومي بدون وجه حق. \n",
            " حتى المنظمات الاجتماعية التي تزعم دفاعها عن القانون والعدل بين المواطنين، على غرار الاتحاد العام التونسي للشغل المنظمة النقابية الأعرق في تونس، رفضت الإذعان لقرار المحكمة الإدارية الصادر قبل بضعة أسابيع، لصالح مرصد رقابة لمكافحة الفساد، الذي يتزعمه المرشح لرئاسة الجمهورية، عماد الدايمي. \n",
            " وهذا ما تعاني منه المحكمة الإدارية منذ عقود. إذ إن اللجوء إليها سهل وميسر، لكن الاحتكام إلى قراراتها وأحكامها في فضّ النزاعات، ما يزال ضعيفًا، إن لم نقل منعدمًا. وهذا ما يطرح سؤالًا جوهريًا حول أسباب ودواعي عدم تنفيذ قرارات المحكمة الإدارية، على الرغم من كل الصلاحيات التي مُنحت لها. \n",
            " في دراسة علمية قانونية نُشرت مؤخرًا حول تنفيذ أحكام وقرارات القضاء الإداري في تونس، أشار القاضي الإداري، عماد الغابري، إلى ما أسماها تفاقم ظاهرة عدم تنفيذ أحكام القضاء الإداري، حتى أصبح يُنعت بالقضاء الذي لا تُنفذ أحكامه وقراراته، وهي الجملة التي تتردد في الواقع على جميع الألسن في تونس، كترجمة عملية على هذه اللامبالاة التي تواجه بها قرارات المحكمة الإدارية.. لامبالاة تضع اليوم مستقبل القضاء الإداري على كفّ عِفريت. \n",
            " لم ينتهِ النقاش عند عدم تنفيذ قرارات المحكمة الإدارية، إنما تعدّاه ليشمل مسألة الولاية على المسار الانتخابي، وسط تمسك المحكمة بأحقيتها القانونية على هذا الأمر. لكن هيئة الانتخابات كانت قد سبقت الجميع إلى ذلك منذ البداية، من خلال إعلان ولايتها بالكامل على العملية الانتخابية. \n",
            " فهي المحددة لرزنامة الانتخابات، وهي من تقرر تاريخ يوم الاقتراع، وهي من تشرف على عملية التصويت، ومن تعلن عن نتائجه النهائية. وزادت على ذلك، بأن أعطت لنفسها حق الولاية على الإعلام والمؤسسات الإعلامية، بل حتى على المادة الإعلامية المرشحة للبثّ، وعلى ما يُقال في بعض المنابر الإعلامية، خصوصًا الانتقادات التي توجّه إلى الهيئة. \n",
            " ليس هذا وحسب، بل إن هيئة الانتخابات أعلنت ولايتها على مشاركة المنظمات المختصة في مراقبة الانتخابات، مثل منظمتَي أنا يقظ ومراقبون، واتهمتهما بالفساد المالي، بناءً على ما قالت إنها إشعارات من السلطات الرسمية بحصولهما على تمويل أجنبي. هذا يعني أن الهيئة استحوذت حتى على دور القضاء، المخول وحده بتأكيد أو نفي تهمة الفساد المالي على المنظمتين. \n",
            " هذا النزوع للهيمنة على العملية الانتخابية، واستبعاد المحكمة الإدارية من مجالات اختصاصها المنصوص عليها قانونًا في علاقة بالانتخابات، جعلا العديد من الخبراء وأساتذة القانون يخرجون عن صمتهم، ويعبّرون عن رفضهم ذلك بوضوح. \n",
            " فقد اعتبر الأستاذ كمال بن مسعود، المتخصص في القضاء الإداري، أن المحكمة الإدارية تتمتع بالولاية الكاملة على الانتخابات، خصوصًا في النزاعات الانتخابية والأحكام القضائية الباتّة الصادرة عنها، وهو ما أكده عدد من المختصين في القانون الدستوري، في بيان نُشر الأسبوع المنقضي في عدة منابر إعلامية تونسية وأجنبية. \n",
            " لا يقتصر المشكل على الولاية على الانتخابات، أو على مكانة القضاء الإداري، أو على مجالات تنفيذ قرارات المحكمة الإدارية. فتلك هي الشجرة التي تخفي الغابة، كما يقال. الأمر يتعلق بمشكلة سياسية في العمق، ترتبط بالإرادة السياسية في المحاكمات العادلة، وجعل القضاء هو الفيصل في النزاعات بين السلطة وخصومها، وتحقيق استقلال المؤسسة القضائية، وضمان مبدأ الفصل بين السلطات، وحماية الحقوق المدنية والسياسية، والحريات بجميع تمظهراتها. \n",
            " هذا ما تعكسه المعارك الحقيقية اليوم، التي يبدو أن ملف المحكمة الإدارية ليس سوى جزء من كل، على رأي المناطقة القدماء. \n",
            " إن الأمر يتعلق بنزوع السلطة التنفيذية تاريخيًا وحاضرًا إلى الهيمنة على المؤسسة القضائية بشكل عام. فمنذ نشأة القضاء في تونس في نهاية خمسينيات القرن الماضي، وهو محكوم بلعبة الشد والجذب مع السلطة الحاكمة، التي نزعت عبر التاريخ التونسي الحديث والمعاصر إلى الهيمنة على المرفق القضائي وسلبه استقلاليته. بدءًا بحكم الرئيس الراحل الحبيب بورقيبة، حيث كان يسمى قضاء الزعيم، مرورًا بفترة ح```json{\"story_title\": \"الجدل حول استقلال السلطة القضائية في تونس وتأثيره على الانتخابات\", \"story_keywords\": [\"تونس\", \"السلطة القضائية\", \"الانتخابات\", \"قيس سعيّد\", \"المحكمة الإدارية\"], \"story_summary\": [\"تزايد الحديث عن استقلال السلطة القضائية في تونس.\", \"الهيئة العليا للانتخابات تواجه انتقادات بسبب إقصاء مرشحين.\", \"المحكمة الإدارية تقبل طعون المرشحين وتعيدهم للسباق الانتخابي.\", \"السلطة التنفيذية تُتهم بالهيمنة على القضاء.\", \"استطلاعات الرأي تظهر تراجع شعبية الرئيس سعيّد.\"], \"story_category\": \"politics\", \"story_entities\": [{\"entity_value\": \"تونس\", \"entity_type\": \"location\"}, {\"entity_value\": \"قيس سعيّد\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"فاروق بوعسكر\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عماد الدايمي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"منذر الزنايدي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عبد اللطيف المكي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"المحكمة الإدارية\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الهيئة العليا للانتخابات\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الاتحاد العام التونسي للشغل\", \"entity_type\": \"organization\"}, {\"entity_value\": \"ثورة 14 يناير\", \"entity_type\": \"event\"}]}```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 4913, 26485, 6112, 788, 330, 31382, 125510, 8532, 128967, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 37524, 133877, 16157, 128248, 138752, 497, 330, 26485, 51354, 788, 4383, 135564, 20064, 497, 330, 31382, 123993, 124917, 142887, 126510, 497, 330, 31382, 127570, 47632, 497, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 31382, 134700, 124058, 125573, 73441, 7914, 330, 26485, 27251, 788, 4383, 14293, 130010, 123980, 131801, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 10465, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 39434, 131377, 12961, 124126, 27490, 132070, 130153, 85153, 125669, 98719, 128707, 32790, 133955, 10465, 330, 31382, 134700, 124058, 125573, 73441, 39434, 125267, 124665, 135590, 125637, 32790, 133955, 37524, 124464, 14558, 91335, 10176, 125006, 124125, 124181, 138751, 14558, 10465, 330, 31382, 123993, 124917, 140597, 55334, 73441, 39434, 64604, 129080, 124476, 126992, 123904, 25871, 128248, 124172, 127288, 10465, 330, 124341, 43635, 80970, 23224, 47632, 124269, 69682, 14558, 39434, 129198, 39434, 127923, 52157, 124232, 73441, 126543, 59842, 125090, 73771, 13325, 1189, 1125, 330, 26485, 11847, 788, 330, 9896, 46979, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 135564, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 127521, 124085, 27846, 124179, 126023, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 124423, 65398, 124220, 5703, 135063, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 123904, 127188, 125572, 124104, 133065, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 136961, 124478, 43635, 124394, 53479, 124811, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 31382, 134700, 124058, 125573, 73441, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 127137, 128586, 143826, 125006, 138391, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 84532, 125520, 220, 16, 19, 134340, 497, 330, 2996, 1819, 788, 330, 3087, 9207, 60, 5541, 13874, 151645, 198]\n",
            "labels:\n",
            "```json{\"story_title\": \"الجدل حول استقلال السلطة القضائية في تونس وتأثيره على الانتخابات\", \"story_keywords\": [\"تونس\", \"السلطة القضائية\", \"الانتخابات\", \"قيس سعيّد\", \"المحكمة الإدارية\"], \"story_summary\": [\"تزايد الحديث عن استقلال السلطة القضائية في تونس.\", \"الهيئة العليا للانتخابات تواجه انتقادات بسبب إقصاء مرشحين.\", \"المحكمة الإدارية تقبل طعون المرشحين وتعيدهم للسباق الانتخابي.\", \"السلطة التنفيذية تُتهم بالهيمنة على القضاء.\", \"استطلاعات الرأي تظهر تراجع شعبية الرئيس سعيّد.\"], \"story_category\": \"politics\", \"story_entities\": [{\"entity_value\": \"تونس\", \"entity_type\": \"location\"}, {\"entity_value\": \"قيس سعيّد\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"فاروق بوعسكر\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عماد الدايمي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"منذر الزنايدي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عبد اللطيف المكي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"المحكمة الإدارية\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الهيئة العليا للانتخابات\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الاتحاد العام التونسي للشغل\", \"entity_type\": \"organization\"}, {\"entity_value\": \"ثورة 14 يناير\", \"entity_type\": \"event\"}]}```<|im_end|>\n",
            "\n",
            "[INFO|configuration_utils.py:752] 2025-08-12 01:38:40,348 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:817] 2025-08-12 01:38:40,350 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.55.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|2025-08-12 01:38:40] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2292, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2322, in _get_module\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2320, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/gemma3n/configuration_gemma3n.py\", line 31, in <module>\n",
            "    from timm.data import ImageNetInfo, infer_imagenet_subset\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/timm/__init__.py\", line 2, in <module>\n",
            "    from .layers import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/__init__.py\", line 23, in <module>\n",
            "    from .classifier import create_classifier, ClassifierHead, NormMlpClassifierHead, ClNormMlpClassifierHead\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/classifier.py\", line 15, in <module>\n",
            "    from .create_norm import get_norm_layer\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/timm/layers/create_norm.py\", line 29, in <module>\n",
            "    from torchvision.ops.misc import FrozenBatchNorm2d\n",
            "ModuleNotFoundError: No module named 'torchvision'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/content/LLaMA-Factory/src/llamafactory/cli.py\", line 151, in main\n",
            "    COMMAND_MAP[command]()\n",
            "  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 110, in run_exp\n",
            "    _training_function(config={\"args\": args, \"callbacks\": callbacks})\n",
            "  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 72, in _training_function\n",
            "    run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n",
            "  File \"/content/LLaMA-Factory/src/llamafactory/train/sft/workflow.py\", line 52, in run_sft\n",
            "    model = load_model(tokenizer, model_args, finetuning_args, training_args.do_train)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/LLaMA-Factory/src/llamafactory/model/loader.py\", line 159, in load_model\n",
            "    if type(config) in AutoModelForImageTextToText._model_mapping.keys():  # image-text\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 820, in keys\n",
            "    mapping_keys = [\n",
            "                   ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 821, in <listcomp>\n",
            "    self._load_attr_from_module(key, name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 817, in _load_attr_from_module\n",
            "    return getattribute_from_module(self._modules[module_name], attr)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\", line 729, in getattribute_from_module\n",
            "    if hasattr(module, attr):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 2295, in __getattr__\n",
            "    raise ModuleNotFoundError(\n",
            "ModuleNotFoundError: Could not import module 'Gemma3nConfig'. Are this object's requirements defined correctly?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "Z1pkVuuW7SQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(base_model_id,\n",
        "                                             device_map=\"auto\",\n",
        "                                             torch_dtype=torch_dtype )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
      ],
      "metadata": {
        "id": "Xye58QnTc-AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetiuned_model_id = \"/gdrive/MyDrive/llm_finetuning/models/\"\n",
        "model.load_adapter(finetiuned_model_id)"
      ],
      "metadata": {
        "id": "0ETMe-MC7xFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(details_extraction_messages,tokenize=False,add_generation_prompt=True)\n",
        "\n",
        "\n",
        "model_inputs = tokenizer([text],return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens = 1024,\n",
        "    do_sample = False , top_k = None , temperature = None , top_p= None\n",
        ")\n",
        "\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids ,output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "\n",
        "response  = tokenizer.batch_decode(generated_ids,skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "mFjH9hsT7m9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# vLLM\n"
      ],
      "metadata": {
        "id": "u8vYj24O-7WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "adapter_model_id = \"/gdrive/MyDrive/llm_finetuning/models/\"\n",
        "\n",
        "!nohup vllm serve \"{base_model_id}\" --dtype=half --gpu-memory-utilization 0.8 --max_lora_rank 64 --enable-lora --lora-modules news-lora=\"{adapter_model_id}\" &\n"
      ],
      "metadata": {
        "id": "ck_7sR6g-8oP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "TBZ2Du8tdjSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(\n",
        "    translation_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")"
      ],
      "metadata": {
        "id": "n6Gor_fVdW-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vllm_model_id = \"news-lora\"\n",
        "\n",
        "llm_response = requests.post(\"http://localhost:8000/v1/completions\", json={\n",
        "    \"model\": vllm_model_id,\n",
        "    \"prompt\": prompt,\n",
        "    \"max_tokens\": 1000,\n",
        "    \"temperature\": 0.3\n",
        "})\n",
        "\n",
        "llm_response.json()"
      ],
      "metadata": {
        "id": "JYPDkJ_Adp7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "864ecc052d58413a8acc752519e7a47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90d156ecc9a44085b7190d0b065212ab",
              "IPY_MODEL_eab6e07a210b4b639734c38fecb26dc4",
              "IPY_MODEL_9ef4bd1849d74e9db1f1d653885bd975"
            ],
            "layout": "IPY_MODEL_b51565f2672b411a9664ad4f1b3b531a"
          }
        },
        "90d156ecc9a44085b7190d0b065212ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_902bfcbe5035452a8d39e07d9584d3e1",
            "placeholder": "​",
            "style": "IPY_MODEL_1a33c6764cc0449e8217b02318f6c41d",
            "value": "config.json: 100%"
          }
        },
        "eab6e07a210b4b639734c38fecb26dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5626daa64994846b476b7d02554a1d1",
            "max": 660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f55d96d87ec44ebeba9ce8683df969b8",
            "value": 660
          }
        },
        "9ef4bd1849d74e9db1f1d653885bd975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c3c7bab5eb4e888d9eac1709471906",
            "placeholder": "​",
            "style": "IPY_MODEL_db626773e0fc4e668ab4c45a15d87f36",
            "value": " 660/660 [00:00&lt;00:00, 68.6kB/s]"
          }
        },
        "b51565f2672b411a9664ad4f1b3b531a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "902bfcbe5035452a8d39e07d9584d3e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a33c6764cc0449e8217b02318f6c41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5626daa64994846b476b7d02554a1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55d96d87ec44ebeba9ce8683df969b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8c3c7bab5eb4e888d9eac1709471906": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db626773e0fc4e668ab4c45a15d87f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9944fd5cd094aa5ad6e30a798be9ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b41a047909784a5091d87ded5d058022",
              "IPY_MODEL_d28fb8e5fff64c009000836279006db9",
              "IPY_MODEL_ce0f28777804493e8641491a2e32fb36"
            ],
            "layout": "IPY_MODEL_60575ff969014494958e352858491ab2"
          }
        },
        "b41a047909784a5091d87ded5d058022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ba906bf51cd4983b6d3a12971a590de",
            "placeholder": "​",
            "style": "IPY_MODEL_43aea7b85f9748d997320884c465d328",
            "value": "model.safetensors: 100%"
          }
        },
        "d28fb8e5fff64c009000836279006db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e193935ec2743a88b3d6a4462923e62",
            "max": 3087467144,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c457aa6032f54b488e3c32265be37299",
            "value": 3087467144
          }
        },
        "ce0f28777804493e8641491a2e32fb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d525811d178f4133994e0c438c18efe8",
            "placeholder": "​",
            "style": "IPY_MODEL_4906a5277ed546099a46e467550dbaa0",
            "value": " 3.09G/3.09G [01:13&lt;00:00, 110MB/s]"
          }
        },
        "60575ff969014494958e352858491ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ba906bf51cd4983b6d3a12971a590de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43aea7b85f9748d997320884c465d328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e193935ec2743a88b3d6a4462923e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c457aa6032f54b488e3c32265be37299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d525811d178f4133994e0c438c18efe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4906a5277ed546099a46e467550dbaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2279bc685f242a8a06f1c21dd67608f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_447a9a3bb8774752ad670c44607af2b1",
              "IPY_MODEL_4bc177ccfcd34ca983e5869ab63c65ee",
              "IPY_MODEL_2d9c684cd9184fa0b13528b84bb047cb"
            ],
            "layout": "IPY_MODEL_eb25870093a3445f8dc8610c06191756"
          }
        },
        "447a9a3bb8774752ad670c44607af2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5f56e6280b46a3bc20add17092173a",
            "placeholder": "​",
            "style": "IPY_MODEL_cdde4c9eb4284db3bcbd6df9d0fce9db",
            "value": "generation_config.json: 100%"
          }
        },
        "4bc177ccfcd34ca983e5869ab63c65ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413cb8a0796f4079b8b8beb569b21008",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3b86af0e77c4a1fa18f5b06c8b94896",
            "value": 242
          }
        },
        "2d9c684cd9184fa0b13528b84bb047cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c02fa480cc49629a209f34f58bd135",
            "placeholder": "​",
            "style": "IPY_MODEL_dacbbc6d4f1c41d8a5d686ae71653654",
            "value": " 242/242 [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "eb25870093a3445f8dc8610c06191756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5f56e6280b46a3bc20add17092173a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdde4c9eb4284db3bcbd6df9d0fce9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "413cb8a0796f4079b8b8beb569b21008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3b86af0e77c4a1fa18f5b06c8b94896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53c02fa480cc49629a209f34f58bd135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dacbbc6d4f1c41d8a5d686ae71653654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afcafae734ac4cb6867ada6b908bf25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93ed3548aaec4df0a9cc83fe34049786",
              "IPY_MODEL_a661bf16093d4b6cab316d71e1e54ccd",
              "IPY_MODEL_0688737867ca4b3fbbc3d5b1becb2319"
            ],
            "layout": "IPY_MODEL_32d880c177c54252ac7d39929c8bb9dd"
          }
        },
        "93ed3548aaec4df0a9cc83fe34049786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d59f47a3144f84a53d12a87f7e0dfe",
            "placeholder": "​",
            "style": "IPY_MODEL_22c10e01751b487e8af30a7d7663b425",
            "value": "tokenizer_config.json: "
          }
        },
        "a661bf16093d4b6cab316d71e1e54ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fece776d690b4f089fa0c696e3e91fb9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_063767c8625547c39e6f7f29bd169846",
            "value": 1
          }
        },
        "0688737867ca4b3fbbc3d5b1becb2319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22fbe4086304c01a7ccd4058630aab3",
            "placeholder": "​",
            "style": "IPY_MODEL_717e5b7d046f47c9875925bd2dc23f7f",
            "value": " 7.30k/? [00:00&lt;00:00, 358kB/s]"
          }
        },
        "32d880c177c54252ac7d39929c8bb9dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d59f47a3144f84a53d12a87f7e0dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c10e01751b487e8af30a7d7663b425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fece776d690b4f089fa0c696e3e91fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "063767c8625547c39e6f7f29bd169846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e22fbe4086304c01a7ccd4058630aab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717e5b7d046f47c9875925bd2dc23f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06ef0e1f73a41c2ac9bbe36a7c3e79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cd1fee0f5394ab8a8d86906d948ae72",
              "IPY_MODEL_d866a05da1d64761ae5d583c63a5ab64",
              "IPY_MODEL_133ea324a8ff4a468d7316f919c2825d"
            ],
            "layout": "IPY_MODEL_e284623ee825469a90e0dde68d69af2f"
          }
        },
        "4cd1fee0f5394ab8a8d86906d948ae72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24f4df5bcba7465f93445d4da7eeec52",
            "placeholder": "​",
            "style": "IPY_MODEL_cf37014fbd5842ea82451b0fe2f1bf9e",
            "value": "vocab.json: "
          }
        },
        "d866a05da1d64761ae5d583c63a5ab64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c555c7ee2df42cea26e70a2f7d7f40f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e9873185d4e427b8ada997fa4bf7fba",
            "value": 1
          }
        },
        "133ea324a8ff4a468d7316f919c2825d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee56791e225c453e97e9a3083c5be31a",
            "placeholder": "​",
            "style": "IPY_MODEL_90157a71e7114df29a89fb50aef2963d",
            "value": " 2.78M/? [00:00&lt;00:00, 4.28MB/s]"
          }
        },
        "e284623ee825469a90e0dde68d69af2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f4df5bcba7465f93445d4da7eeec52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf37014fbd5842ea82451b0fe2f1bf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c555c7ee2df42cea26e70a2f7d7f40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4e9873185d4e427b8ada997fa4bf7fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee56791e225c453e97e9a3083c5be31a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90157a71e7114df29a89fb50aef2963d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2aa58f9d610496e81bdd36592688843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f887371cee54c0e87a45c11ae5ee46a",
              "IPY_MODEL_bdaf52fd1c7e407fa00f8fc06c6ccead",
              "IPY_MODEL_612b049be5874b8ea37c0038679708f4"
            ],
            "layout": "IPY_MODEL_d1d0dbe7407f4a8d967de45bed49c33e"
          }
        },
        "7f887371cee54c0e87a45c11ae5ee46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7252f2a73943c8aeaac9123db557b3",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c68da166074e70ad196afef1629e0f",
            "value": "merges.txt: "
          }
        },
        "bdaf52fd1c7e407fa00f8fc06c6ccead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e0120e0ef24241899c589b09515f53",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1be8400fbb8349e78b31b9ed6504d882",
            "value": 1
          }
        },
        "612b049be5874b8ea37c0038679708f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21659e428d54797a51f4e4180c459f7",
            "placeholder": "​",
            "style": "IPY_MODEL_2f2c2ee2187f49d2adca17371aa83f73",
            "value": " 1.67M/? [00:00&lt;00:00, 4.26MB/s]"
          }
        },
        "d1d0dbe7407f4a8d967de45bed49c33e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7252f2a73943c8aeaac9123db557b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c68da166074e70ad196afef1629e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08e0120e0ef24241899c589b09515f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1be8400fbb8349e78b31b9ed6504d882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e21659e428d54797a51f4e4180c459f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2c2ee2187f49d2adca17371aa83f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c44acac89047f49e2726a94ab8128d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8857c22226a4e75a0661f7e9d07df22",
              "IPY_MODEL_efe913e545a2468fb0861426a9aff987",
              "IPY_MODEL_f390b3745dc14504aa4b371d8a52735b"
            ],
            "layout": "IPY_MODEL_dd1f273b2ec549fb84abbb3911714bf5"
          }
        },
        "e8857c22226a4e75a0661f7e9d07df22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2020ca7713884e5e881ad5f1ebf21192",
            "placeholder": "​",
            "style": "IPY_MODEL_985b965e0bbb418689339b77de6f2cde",
            "value": "tokenizer.json: "
          }
        },
        "efe913e545a2468fb0861426a9aff987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e179c98210c46739003e7e24160c557",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95ff72c7c7ec4368b97bf8b33736cfed",
            "value": 1
          }
        },
        "f390b3745dc14504aa4b371d8a52735b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52ee30aad324ca2b14c4800fc626720",
            "placeholder": "​",
            "style": "IPY_MODEL_82c0198710a64556a6f573c80c62f696",
            "value": " 7.03M/? [00:00&lt;00:00, 14.7MB/s]"
          }
        },
        "dd1f273b2ec549fb84abbb3911714bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2020ca7713884e5e881ad5f1ebf21192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "985b965e0bbb418689339b77de6f2cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e179c98210c46739003e7e24160c557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "95ff72c7c7ec4368b97bf8b33736cfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f52ee30aad324ca2b14c4800fc626720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c0198710a64556a6f573c80c62f696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}